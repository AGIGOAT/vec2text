{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4206ccac-9fc8-4a1b-b22f-b0bb6c1b4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f443afa7-bdbd-4c85-abf8-effe715d513e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loading model from checkpoint: /home/jxm3/research/retrieval/inversion/saves/db66b9c01b644541fedbdcc59c53a285/ebb31d91810c4b62d2b55b5382e8c7ea/checkpoint-999744\n",
      "Set train_args.dataloader_num_workers = 4\n",
      "[1] creating model & stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/emb_inv_dpr/nq-train/cache-6af83e39f92acf9e.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/emb_inv_dpr/nq-dev/cache-8796b523fc1740bd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] tokenizing dataset & preprocessing embeddings\n",
      "[3] initializing trainer\n",
      "[4] getting ckpnt\n",
      "[5] loading ckpt /home/jxm3/research/retrieval/inversion/saves/db66b9c01b644541fedbdcc59c53a285/ebb31d91810c4b62d2b55b5382e8c7ea/checkpoint-999744\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating from val:   0%|                                                                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate() -- embedder_decode_score False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating from val:  33%|███████████████████████████▋                                                       | 1/3 [00:00<00:01,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate() -- embedder_decode_score False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating from val:  67%|███████████████████████████████████████████████████████▎                           | 2/3 [00:01<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate() -- embedder_decode_score False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the character of the skull, which are relatively smooth and untutored in the case of infant sutures. Nevertheless, the sutures\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual from the Southern Hemisphere to win the Winter Olympic relay gold medal, and was also part of the Australian Short Track team which won a\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same rights as men, and 75% agreed that they should be protected from discrimination. Among the other 15% are heterosexuals, no work\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating from train:   0%|                                                                                     | 0/41656 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate() -- embedder_decode_score False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0522613525390625,\n",
       " 'eval_bleu_score': 31.552541624779003,\n",
       " 'eval_accuracy': 0.7386067708333334,\n",
       " 'eval_perplexity': 2.8641205867926014,\n",
       " 'eval_runtime': 5.4294,\n",
       " 'eval_samples_per_second': 92.091,\n",
       " 'eval_steps_per_second': 0.737}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import analyze_utils\n",
    "\n",
    "# https://wandb.ai/jack-morris/emb-inv-1/runs/ebb31d91810c4b62d2b55b5382e8c7ea/logs?workspace=user-jxmorris12\n",
    "checkpoint_folder = '/home/jxm3/research/retrieval/inversion/saves/db66b9c01b644541fedbdcc59c53a285/ebb31d91810c4b62d2b55b5382e8c7ea'\n",
    "args_str = '--per_device_train_batch_size 128 --per_device_eval_batch_size 128 --max_seq_length 32 --model_name_or_path t5-base --embedder_model_name gtr_base --num_repeat_tokens 16 --embedder_no_grad True --exp_group_name mar17-baselines --learning_rate 0.0003 --freeze_strategy none --embedder_fake_with_zeros False --use_frozen_embeddings_as_input False --num_train_epochs 24 --max_eval_samples 500 --eval_steps 25000 --warmup_steps 100000 --bf16=1 --use_wandb=1'\n",
    "trainer = analyze_utils.load_inversion_model_and_trainer(checkpoint_folder, args_str)\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6958c73-de45-4f0b-b254-f1a1a8d41fe7",
   "metadata": {},
   "source": [
    "## checking with sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8dd3a28-fd3c-40c2-885b-ffe820382faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(trainer.get_eval_dataloader()))\n",
    "true_text = trainer.model.embedder_tokenizer.batch_decode(batch['embedder_input_ids'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "775b7715-a917-444b-abb7-a264cdda0118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a5f56c4117402dbd0c419c1607dd57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a2d19/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fffd1dd7e284fbf97b3d8e45fa028eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c734c4983fce45a2adb05c50b50e8a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)17900a2d19/README.md:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32b770a313c4bed875cc7bf554c51db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)900a2d19/config.json:   0%|          | 0.00/540 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7869a3376044cb9aaf0b30d52eafb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d1b3529443486bb99e33fa62486e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b36e277539c4776bb2a32b82073914a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528c5ea093d44ab09cba13605cfc49ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aedc024d1af4426862de8468288249f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a2d19/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecedae514efc4d6d8210a34ee3285ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/554 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381caf347efa476a8590eb68ac5b6a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)17900a2d19/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99447d7b0aac4d079aa9a14d6b7df6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)00a2d19/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('nq-distilbert-base-v1')\n",
    "\n",
    "dpr_passage_embedding = model.encode([true_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d7e7b-f090-4605-85ec-2a69ddc49a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:10<00:00,  1.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "gen_kwargs = trainer.gen_kwargs\n",
    "\n",
    "def gen(inputs_embeds: torch.Tensor, attention_mask: torch.Tensor):\n",
    "    inputs_embeds, attention_mask = trainer.model.embed_and_project(\n",
    "        embedder_input_ids=embedder_input_ids.cuda(),\n",
    "        embedder_attention_mask=embedder_attention_mask.cuda(),\n",
    "    )\n",
    "    inputs_embeds += torch.randn(inputs_embeds.shape, device=inputs_embeds.device) * alpha\n",
    "    return trainer.model.encoder_decoder.generate(\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        attention_mask=attention_mask,\n",
    "        **gen_kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e6ad1-e77c-496c-963f-18d56d46e76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
