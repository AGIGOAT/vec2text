{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e82f0d5-9a49-4242-b840-9102a963ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db803ab4-3fa3-4f09-a231-cebc1cb106be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trainer for analysis – setting --do_eval=1\n",
      "loading alias dpr_nq__msl32_beta from /home/jxm3/research/retrieval/inversion/saves/db66b9c01b644541fedbdcc59c53a285/ebb31d91810c4b62d2b55b5382e8c7ea...\n",
      "Set train_args.dataloader_num_workers = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d260dfedba8a4ad984a433a950aa1706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e425b555d7d4445b997b33ab21b621e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9300eb947bf04583bcf075a084895de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8808d56f91094d3b8168441c258ef956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output -> The mlbies wase wyst bograge; And the sliths and toms wre\n",
      "================ End trainer sanity check ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import analyze_utils\n",
    "\n",
    "checkpoint_folder = \"/home/jxm3/research/retrieval/inversion/saves/98b1418d38c3f9333b17ab20bff06ff9/\"\n",
    "trainer = analyze_utils.load_trainer(checkpoint_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c3e6f-4b19-4caa-ae5c-fd224461af79",
   "metadata": {},
   "source": [
    "## hparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f303b7e-6bc6-48c5-a70c-e75f893e6ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the character of the skull, which are relatively smooth and untutuous in the case of infant sutures. Unlike the sutures,\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual hemisphere athlete from Australia to win the Winter Olympic relay, and was part of the Southern Hemisphere team, which won the short\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same rights as men, and 75% agreed that they should be protected from discrimination. Among the other 15%, gay workers are no longer exp\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the character of the skull, which are relatively smooth and untutuous in the case of infant sutures. Unlike the skulls of\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual hemisphere athlete from Australia to win the Winter Olympic relay, and was part of the Southern Hemisphere team, which won the short\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same rights as straight people, and 7% agreed that they should be protected from discrimination. Among the 35%, 15% disagreed with HR\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.                                                         \n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extensitive depasiradically depasi broadlyjudeţul broadly expansion closest together specificallyvocation tocativa strengths whichconnectlatigateemis integral portions alongARE integralDimensiuniencompassingDimensiuniaturaatura\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "emoți conservator incercat sticla gradini parinti orizont parinti gradini sticla sticla sticla sticla incercat (...) To win consumulaparatulbirth within consciousness sticla taiatantesvâr sticla sticla sticla taiat leader\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "organismului suprafaţ galben (+politacît328unicipiuluijudeţul Popescu 8. organismului Stra Orthodrupolis gasest (+6.6 PopescuPopсиkraticunicipiului Popescuunicipiului gasest Popescuunicipiului\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the character of the skull, which are relatively smooth and untutuous in the case of infant sutures. Unlike the sutures,\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual from the Southern Hemisphere to win the Winter Olympic relay gold medal, and was also part of the Australian Short Track team, which won gold\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same rights as men, and 75% agreed that they should be protected from discrimination. Among the other 15%, gay workers are no longer exp\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the character of the skull, which are relatively smooth and untutuous in the case of infant sutures. Unlike the skulls of\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual hemisphere athlete from Australia to win the Winter Olympic relay, and was part of the Southern Hemisphere team, which won the short\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same rights as men, and 75% agreed that they should be protected from discrimination. Among the other 15%, gay workers are no longer exp\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the character of the skull, which are relatively smooth and untural unlike the sutures of the portions of the infant sutures. For instance,\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual swimmer from Australia to win a Winter Olympic medal, and to win the short-season relay gold medal, and was also part of the Warm-\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same percentage as straight people, while 15.33% disagreed and indicated that they should be protected from discrimination or harassment. Eighth percent aligne\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the character of the skull, which are relatively smooth and untutuous in the case of infant sutures. Unlike the sutures,\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual from the Southern Hemisphere to win the Winter Olympic relay gold medal, and was also part of the Australian Short Track team, which won gold\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same rights as men, and 75% agreed that they should be protected from discrimination. Among the other 15%, gay workers are no longer exp\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the character of the skull, which are relatively smooth and untutuous in the case of infant sutures. Unlike the sutures,\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual hemisphere athlete from Australia to win the Winter Olympic relay, and was part of the Southern Hemisphere team, which won the short\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same rights as men, and 75% agreed that they should be protected from discrimination. Among the other 15%, gay workers are no longer exp\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the character of the skull, which are relatively smooth and untutuous in the case of infant sutures. Unlike the skulls of\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual hemisphere athlete from Australia to win the Winter Olympic relay, and was part of the Southern Hemisphere team, which won the short\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same rights as straight people, and 7% agreed that they should be protected from discrimination. Among the 35%, 15% disagreed with HR\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for beta in [1.0, 0.5, 0.1]:\n",
    "    for gamma in [.01, .1, 1.0,]:\n",
    "        print(gamma)\n",
    "        trainer.inversion_trainer.gen_kwargs = {\n",
    "            \"early_stopping\": False,\n",
    "            \"num_beams\": 1,\n",
    "            \"do_sample\": False,\n",
    "            \"no_repeat_ngram_size\": 0,\n",
    "        }\n",
    "        trainer.inversion_trainer.args.per_device_eval_batch_size = 64\n",
    "        trainer.inversion_trainer.generation_strategy = \"contrastive\"\n",
    "        trainer.inversion_trainer.contrastive_generation_alpha = 0.0\n",
    "        trainer.inversion_trainer.contrastive_generation_beta = beta\n",
    "        trainer.inversion_trainer.contrastive_generation_gamma = gamma\n",
    "        trainer.inversion_trainer.contrastive_generation_hypothesis_num_samples = 2\n",
    "        trainer.inversion_trainer.contrastive_generation_num_rounds = 1\n",
    "        metrics = trainer.inversion_trainer.evaluate(\n",
    "            eval_dataset=trainer.eval_dataset[\"nq\"]\n",
    "        )\n",
    "        metrics['beta'] = beta\n",
    "        metrics['gamma'] = gamma\n",
    "        data.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48b6d838-5c2f-4afe-84dc-6f9b5e219066",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for beta in [1.0, 0.5, 0.1]:\n",
    "    for gamma in [.01, .1, 1.0,]:\n",
    "        data[j]['beta'] = beta\n",
    "        data[j]['gamma'] = gamma\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edceeb41-0018-4827-885e-b6832e6201b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_bleu_score</th>\n",
       "      <th>eval_meteor_score</th>\n",
       "      <th>eval_rouge_score</th>\n",
       "      <th>eval_bert_score</th>\n",
       "      <th>eval_emb_cos_sim</th>\n",
       "      <th>eval_perplexity</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.051722</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>31.873040</td>\n",
       "      <td>0.582110</td>\n",
       "      <td>0.645350</td>\n",
       "      <td>0.917574</td>\n",
       "      <td>0.906060</td>\n",
       "      <td>2.862577</td>\n",
       "      <td>29.1788</td>\n",
       "      <td>17.136</td>\n",
       "      <td>0.274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.051722</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>33.001125</td>\n",
       "      <td>0.598502</td>\n",
       "      <td>0.656074</td>\n",
       "      <td>0.920051</td>\n",
       "      <td>0.909388</td>\n",
       "      <td>2.862577</td>\n",
       "      <td>28.8711</td>\n",
       "      <td>17.318</td>\n",
       "      <td>0.277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.051722</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>0.063540</td>\n",
       "      <td>0.024825</td>\n",
       "      <td>0.034587</td>\n",
       "      <td>0.739477</td>\n",
       "      <td>0.194440</td>\n",
       "      <td>2.862577</td>\n",
       "      <td>32.0273</td>\n",
       "      <td>15.612</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.051722</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>31.804502</td>\n",
       "      <td>0.579873</td>\n",
       "      <td>0.644134</td>\n",
       "      <td>0.917504</td>\n",
       "      <td>0.905665</td>\n",
       "      <td>2.862577</td>\n",
       "      <td>29.1862</td>\n",
       "      <td>17.131</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.051722</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>31.887780</td>\n",
       "      <td>0.586260</td>\n",
       "      <td>0.647375</td>\n",
       "      <td>0.918036</td>\n",
       "      <td>0.907824</td>\n",
       "      <td>2.862577</td>\n",
       "      <td>29.4973</td>\n",
       "      <td>16.951</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_loss  eval_accuracy  eval_bleu_score  eval_meteor_score   \n",
       "0   1.051722       0.738002        31.873040           0.582110  \\\n",
       "1   1.051722       0.738002        33.001125           0.598502   \n",
       "2   1.051722       0.738002         0.063540           0.024825   \n",
       "3   1.051722       0.738002        31.804502           0.579873   \n",
       "4   1.051722       0.738002        31.887780           0.586260   \n",
       "\n",
       "   eval_rouge_score  eval_bert_score  eval_emb_cos_sim  eval_perplexity   \n",
       "0          0.645350         0.917574          0.906060         2.862577  \\\n",
       "1          0.656074         0.920051          0.909388         2.862577   \n",
       "2          0.034587         0.739477          0.194440         2.862577   \n",
       "3          0.644134         0.917504          0.905665         2.862577   \n",
       "4          0.647375         0.918036          0.907824         2.862577   \n",
       "\n",
       "   eval_runtime  eval_samples_per_second  eval_steps_per_second  beta  gamma  \n",
       "0       29.1788                   17.136                  0.274   1.0   0.01  \n",
       "1       28.8711                   17.318                  0.277   1.0   0.10  \n",
       "2       32.0273                   15.612                  0.250   1.0   1.00  \n",
       "3       29.1862                   17.131                  0.274   0.5   0.01  \n",
       "4       29.4973                   16.951                  0.271   0.5   0.10  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d768581-d5c8-4ed1-a89e-235f94969267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='eval_bleu_score', ascending=False)[['gamma', 'beta', 'eval_bleu_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef8cc3e8-d8e8-4dc7-8388-89576c6171a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='beta', ylabel='gamma'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(df.pivot(index='gamma', columns='beta', values='eval_bleu_score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4ad65-7914-431f-a67e-32f5a91c56a1",
   "metadata": {},
   "source": [
    "## testing multi-round decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05ca28ae-06f8-4870-b43d-4bfceb378df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to that of the skulls of infant sutures, which are relatively smooth and untidy, despite the character of the skull. Thus\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual hemisphere athlete from Australia to win a Winter Olympic medal, and was part of the Southern Hemisphere relay team, which won\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same rights as heterosexuals, and 75% agreed that they should be protected from discrimination and harassment. A third percent disagreed, with 15%\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0517222881317139,\n",
       " 'eval_accuracy': 0.7380022321428571,\n",
       " 'eval_bleu_score': 35.519346586060166,\n",
       " 'eval_meteor_score': 0.6205339937767889,\n",
       " 'eval_rouge_score': 0.6791500046812591,\n",
       " 'eval_bert_score': 0.9250462216192058,\n",
       " 'eval_emb_cos_sim': 0.9194977283477783,\n",
       " 'eval_perplexity': 2.862577057394165,\n",
       " 'eval_runtime': 42.3922,\n",
       " 'eval_samples_per_second': 11.795,\n",
       " 'eval_steps_per_second': 0.189}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.inversion_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 4,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "trainer.inversion_trainer.args.per_device_eval_batch_size = 64\n",
    "trainer.inversion_trainer.generation_strategy = \"contrastive\"\n",
    "trainer.inversion_trainer.contrastive_generation_alpha = 0.0\n",
    "trainer.inversion_trainer.contrastive_generation_gamma = 0.1\n",
    "trainer.inversion_trainer.contrastive_generation_hypothesis_num_samples = 1\n",
    "trainer.inversion_trainer.contrastive_generation_num_rounds = 1\n",
    "trainer.inversion_trainer.evaluate(\n",
    "    eval_dataset=trainer.eval_dataset[\"nq\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ec6af2-96f4-4e79-b1d3-c50808f29026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to that of the skulls of infant sutures, which are relatively smooth and untidy, despite the character of the skull. Thus\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual from the Southern Hemisphere to win a Winter Olympic gold medal, and was part of the Australian relay team, which won the short track\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same rights as heterosexuals, and 75% agreed that they should be protected from discrimination and harassment. A third percent disagreed, with 15%\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0517222881317139,\n",
       " 'eval_accuracy': 0.7380022321428571,\n",
       " 'eval_bleu_score': 35.50778495813029,\n",
       " 'eval_meteor_score': 0.6201892577206026,\n",
       " 'eval_rouge_score': 0.6806935869112787,\n",
       " 'eval_bert_score': 0.9246933997741767,\n",
       " 'eval_emb_cos_sim': 0.9174511432647705,\n",
       " 'eval_perplexity': 2.862577057394165,\n",
       " 'eval_runtime': 103.3993,\n",
       " 'eval_samples_per_second': 4.836,\n",
       " 'eval_steps_per_second': 0.077}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.inversion_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 4,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "trainer.inversion_trainer.args.per_device_eval_batch_size = 64\n",
    "trainer.inversion_trainer.generation_strategy = \"contrastive\"\n",
    "trainer.inversion_trainer.contrastive_generation_alpha = 0.0\n",
    "trainer.inversion_trainer.contrastive_generation_gamma = 0.1\n",
    "trainer.inversion_trainer.contrastive_generation_hypothesis_num_samples = 1\n",
    "trainer.inversion_trainer.contrastive_generation_num_rounds = 2\n",
    "trainer.inversion_trainer.evaluate(\n",
    "    eval_dataset=trainer.eval_dataset[\"nq\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ce69f49-19d5-49dd-a4f1-e04dc6f47084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to that of the skulls of infant sutures, which are relatively smooth and untidy, despite the character of the skull. Thus\n",
      "to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "individual from the Southern Hemisphere to win a Winter Olympic medal, and was part of the Australian relay team that won the short track gold medal\n",
      "individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "the same rights as heterosexuals, and 75% agreed that they should be protected from discrimination. A third, 15%, disagreed with workplace O\n",
      "the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0517222881317139,\n",
       " 'eval_accuracy': 0.7380022321428571,\n",
       " 'eval_bleu_score': 35.55991535646119,\n",
       " 'eval_meteor_score': 0.6214096962480463,\n",
       " 'eval_rouge_score': 0.6818722219445803,\n",
       " 'eval_bert_score': 0.9253840747156313,\n",
       " 'eval_emb_cos_sim': 0.9218592643737793,\n",
       " 'eval_perplexity': 2.862577057394165,\n",
       " 'eval_runtime': 300.6379,\n",
       " 'eval_samples_per_second': 1.663,\n",
       " 'eval_steps_per_second': 0.027}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.inversion_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 4,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "trainer.inversion_trainer.args.per_device_eval_batch_size = 64\n",
    "trainer.inversion_trainer.generation_strategy = \"contrastive\"\n",
    "trainer.inversion_trainer.contrastive_generation_alpha = 0.0\n",
    "trainer.inversion_trainer.contrastive_generation_gamma = 0.1\n",
    "trainer.inversion_trainer.contrastive_generation_hypothesis_num_samples = 1\n",
    "trainer.inversion_trainer.contrastive_generation_num_rounds = 4\n",
    "trainer.inversion_trainer.evaluate(\n",
    "    eval_dataset=trainer.eval_dataset[\"nq\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f9eb317-8dac-492f-9c50-62e5bcd33127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m trainer\u001b[38;5;241m.\u001b[39minversion_trainer\u001b[38;5;241m.\u001b[39mcontrastive_generation_hypothesis_num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     12\u001b[0m trainer\u001b[38;5;241m.\u001b[39minversion_trainer\u001b[38;5;241m.\u001b[39mcontrastive_generation_num_rounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minversion_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/transformers/trainer.py:2932\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2929\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   2931\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2932\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2933\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2935\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2936\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2940\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2942\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/research/retrieval/inversion/notebooks/../trainers/inversion.py:108\u001b[0m, in \u001b[0;36mInversionTrainer.evaluation_loop\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluation_loop\u001b[39m(\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m transformers\u001b[38;5;241m.\u001b[39mtrainer_utils\u001b[38;5;241m.\u001b[39mEvalLoopOutput:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    Run evaluation and returns metrics.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    Override to compute ppl from eval loss.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     metric_key_prefix \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_key_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/research/retrieval/inversion/notebooks/../trainers/base.py:290\u001b[0m, in \u001b[0;36mBaseTrainer.evaluation_loop\u001b[0;34m(self, dataloader, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m metric_key_prefix \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_key_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# TODO compute some data metrics here too.\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m generation_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_generation_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m generation_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m generation_metrics\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    293\u001b[0m }\n\u001b[1;32m    294\u001b[0m output\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mupdate(generation_metrics)\n",
      "File \u001b[0;32m~/research/retrieval/inversion/notebooks/../trainers/base.py:194\u001b[0m, in \u001b[0;36mBaseTrainer.eval_generation_metrics\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_generation_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataloader: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# Get decoded text. Note that this is different than `preds`, which\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# is used to compute the loss.\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m     preds_sample_list, preds_sample_labels_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_decoded_sequences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# Log BLEU, log table of text.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     decoded_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m    200\u001b[0m         preds_sample_list, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     )\n",
      "File \u001b[0;32m~/research/retrieval/inversion/notebooks/../trainers/base.py:103\u001b[0m, in \u001b[0;36mBaseTrainer._get_decoded_sequences\u001b[0;34m(self, dataloader, n)\u001b[0m\n\u001b[1;32m     99\u001b[0m gen_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m gen_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inputs[\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m ]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 103\u001b[0m     generated_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_cuda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m all_preds\u001b[38;5;241m.\u001b[39mextend(generated_text\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m    107\u001b[0m all_labels\u001b[38;5;241m.\u001b[39mextend(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/research/retrieval/inversion/notebooks/../trainers/inversion.py:32\u001b[0m, in \u001b[0;36mInversionTrainer.generate\u001b[0;34m(self, inputs, generation_kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Dict, generation_kwargs: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontrastive\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_contrastive\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     37\u001b[0m             inputs\u001b[38;5;241m=\u001b[39minputs, generation_kwargs\u001b[38;5;241m=\u001b[39mgeneration_kwargs\n\u001b[1;32m     38\u001b[0m         )\n",
      "File \u001b[0;32m~/research/retrieval/inversion/notebooks/../trainers/inversion.py:63\u001b[0m, in \u001b[0;36mInversionTrainer.generate_contrastive\u001b[0;34m(self, inputs, generation_kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m generation_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrenormalize_logits\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m round_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrastive_generation_num_rounds):\n\u001b[0;32m---> 63\u001b[0m     generations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m round_ \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrastive_generation_num_rounds:\n\u001b[1;32m     67\u001b[0m         contrastive_logits_processor\u001b[38;5;241m.\u001b[39mupdate_hypotheses(\n\u001b[1;32m     68\u001b[0m             hypotheses\u001b[38;5;241m=\u001b[39mgenerations,\n\u001b[1;32m     69\u001b[0m         )\n",
      "File \u001b[0;32m~/research/retrieval/inversion/notebooks/../models/inversion.py:332\u001b[0m, in \u001b[0;36mInversionModel.generate\u001b[0;34m(self, inputs, generation_kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_decoder\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# required: input embeddings\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgeneration_kwargs,\n\u001b[1;32m    330\u001b[0m     )\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# required: input embeddings\u001b[39;49;00m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# optional: input IDs (for starting generation).\u001b[39;49;00m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# typically not set unless generating prefixes for\u001b[39;49;00m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# reranking.\u001b[39;49;00m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/transformers/generation/utils.py:1490\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1484\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1485\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1486\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1487\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1488\u001b[0m     )\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;66;03m# 13. run beam search\u001b[39;00m\n\u001b[0;32m-> 1490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   1504\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/transformers/generation/utils.py:2763\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2760\u001b[0m next_token_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m   2761\u001b[0m \u001b[38;5;66;03m# hack: adjust tokens for Marian. For Marian we have to make sure that the `pad_token_id`\u001b[39;00m\n\u001b[1;32m   2762\u001b[0m \u001b[38;5;66;03m# cannot be generated both before and after the `nn.functional.log_softmax` operation.\u001b[39;00m\n\u001b[0;32m-> 2763\u001b[0m next_token_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjust_logits_during_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_token_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2764\u001b[0m next_token_scores \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlog_softmax(\n\u001b[1;32m   2765\u001b[0m     next_token_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2766\u001b[0m )  \u001b[38;5;66;03m# (batch_size * num_beams, vocab_size)\u001b[39;00m\n\u001b[1;32m   2768\u001b[0m next_token_scores_processed \u001b[38;5;241m=\u001b[39m logits_processor(input_ids, next_token_scores)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/transformers/generation/utils.py:558\u001b[0m, in \u001b[0;36mGenerationMixin.adjust_logits_during_generation\u001b[0;34m(self, logits, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_initialize_input_ids_for_generation(inputs, bos_token_id, model_kwargs)\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs, input_name, model_kwargs\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjust_logits_during_generation\u001b[39m(\u001b[38;5;28mself\u001b[39m, logits: torch\u001b[38;5;241m.\u001b[39mFloatTensor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;124;03m    Implement in subclasses of [`PreTrainedModel`] for custom behavior to adjust the logits in the generate method.\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.inversion_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 4,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "trainer.inversion_trainer.args.per_device_eval_batch_size = 64\n",
    "trainer.inversion_trainer.generation_strategy = \"contrastive\"\n",
    "trainer.inversion_trainer.contrastive_generation_alpha = 0.0\n",
    "trainer.inversion_trainer.contrastive_generation_gamma = 0.1\n",
    "trainer.inversion_trainer.contrastive_generation_hypothesis_num_samples = 1\n",
    "trainer.inversion_trainer.contrastive_generation_num_rounds = 8\n",
    "trainer.inversion_trainer.evaluate(\n",
    "    eval_dataset=trainer.eval_dataset[\"nq\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f2684-72c8-456c-bd5b-b5be0e5a3716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
