{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e63ec95-eee0-43b9-8d2f-e0567e71c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import sys\n",
    "# sys.path = ['/home/jxm3/research/retrieval/inversion'] + sys.path\n",
    "sys.path = [\n",
    "    p for p in sys.path\n",
    "    if p not in ['/home/jxm3/research/prompting/imodelsX', '/home/jxm3/research/prompting/tree-prompt']\n",
    "]\n",
    "sys.path.append('/home/jxm3/research/retrieval/inversion')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfbcea5-2cd1-4c4c-9cc9-b2056c2664ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_index</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.15197467803955078, -0.28477445244789124, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  query_index                                          embedding\n",
       "0           0            2  [0.15197467803955078, -0.28477445244789124, 0...."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emb_df = pd.read_csv(\"/home/jxm3/research/retrieval/2023_05_15_luar_embedding_list.csv\")\n",
    "emb_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462d7670-21eb-4506-ad71-a549b68f3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = emb_df[\"embedding\"].tolist()\n",
    "embeddings = list(map(eval, embeddings))\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d702bdb-d571-4300-a7fc-dd7aa8d81777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set train_args.dataloader_num_workers = 4\n",
      "Loading trainer for analysis â€“ setting --do_eval=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6f591a51ab4cfb8db0fc4f255747ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1089648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/169936 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f40f0d431e4f66b1d59fd0b4ca9c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1103a148eb394e0c9690eee5dccf0b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900a592d51854bb2b49e4b49f8505a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca21dd90e0742deabda5773ee8e80e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/72831 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_perplexity': -1,\n",
       " 'eval_runtime': 0.0075,\n",
       " 'eval_samples_per_second': 667.755,\n",
       " 'eval_steps_per_second': 133.551}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# luar model with msl 128:\n",
    "# https://wandb.ai/jack-morris/emb-inv-1/runs/a812ef9463f48360967d375c924c461e/overview?workspace=user-jxmorris12\n",
    "\n",
    "\n",
    "import analyze_utils\n",
    "\n",
    "checkpoint_folder = '/home/jxm3/research/retrieval/inversion/saves/947b54370a00d767cb28b2e71a2645b0/a812ef9463f48360967d375c924c461e'\n",
    "args_str = '--per_device_train_batch_size 128 --per_device_eval_batch_size 128 --max_seq_length 128 --model_name_or_path t5-base --embedder_model_name paraphrase-distilroberta --num_repeat_tokens 16 --embedder_no_grad True --exp_group_name mar15-luar --learning_rate 0.0002 --freeze_strategy none --embedder_fake_with_zeros False --num_train_epochs 24 --max_eval_samples 1000 --eval_steps 4000 --warmup_steps 100000 --bf16=1 --use_wandb=1 --dataset_name luar_reddit --use_frozen_embeddings_as_input True --exp_name luar128'\n",
    "trainer = analyze_utils.load_trainer(checkpoint_folder, args_str, sanity_decode=False)\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56be7cd-da3d-4171-99c3-4fc3997ed84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_perplexity': -1,\n",
       " 'eval_runtime': 0.007,\n",
       " 'eval_samples_per_second': 712.832,\n",
       " 'eval_steps_per_second': 142.566}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1b3398a-9ced-4a0c-b2e2-bee3c4206d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "emb_dataloader = torch.utils.data.DataLoader(\n",
    "    embeddings,\n",
    "    batch_size=trainer.args.eval_batch_size,\n",
    "    num_workers=trainer.args.dataloader_num_workers,\n",
    "    pin_memory=trainer.args.dataloader_pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "099c3ec7-6dc7-4804-9879-b3a0136504e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.53s/it]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import tqdm\n",
    "\n",
    "output_text = []\n",
    "\n",
    "gen_kwargs = copy.copy(trainer.gen_kwargs)\n",
    "for emb_batch in tqdm.tqdm(emb_dataloader):\n",
    "    inputs = { \"frozen_embeddings\": emb_batch.float(), \"embedder_input_ids\": torch.ones(len(emb_batch)), \"embedder_attention_mask\": torch.ones(len(emb_batch)) }\n",
    "    inputs_cuda = {k: v.to(trainer.args.device) for k, v in inputs.items()}\n",
    "    gen_kwargs[\"max_length\"] = 128\n",
    "    generated_ids = trainer.generate(\n",
    "        inputs=inputs_cuda, generation_kwargs=gen_kwargs\n",
    "    )\n",
    "    output_text.extend(\n",
    "        trainer.embedder_tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "186a52ff-1fc5-4196-b4c0-1709795d510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_and_embeddings = pd.DataFrame(\n",
    "    zip(output_text, embeddings), columns=['text', 'embedding']\n",
    ")\n",
    "text_and_embeddings.to_parquet('2023_05_15_luar_reconstruction.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f884bec-b7c7-4c46-8b8c-7a7b183db560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ï¿½ does if it Hak his to of product women by hi...</td>\n",
       "      <td>[0.19542090594768524, 0.030160320922732353, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>during toode theï¿½ place asen) of manager's of...</td>\n",
       "      <td>[-0.29221123456954956, -0.1277933418750763, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ï¿½ place it from to operating,'m has you people...</td>\n",
       "      <td>[-0.12761323153972626, -0.047798529267311096, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9 from to if and making's protections fight it...</td>\n",
       "      <td>[0.34192952513694763, 0.04247118532657623, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>during bye over and making's of Glasgow of ge...</td>\n",
       "      <td>[-0.03345293179154396, -0.19010047614574432, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   \n",
       "21  ï¿½ does if it Hak his to of product women by hi...  \\\n",
       "22   during toode theï¿½ place asen) of manager's of...   \n",
       "23  ï¿½ place it from to operating,'m has you people...   \n",
       "24  9 from to if and making's protections fight it...   \n",
       "25   during bye over and making's of Glasgow of ge...   \n",
       "\n",
       "                                            embedding  \n",
       "21  [0.19542090594768524, 0.030160320922732353, 0....  \n",
       "22  [-0.29221123456954956, -0.1277933418750763, 0....  \n",
       "23  [-0.12761323153972626, -0.047798529267311096, ...  \n",
       "24  [0.34192952513694763, 0.04247118532657623, 0.0...  \n",
       "25  [-0.03345293179154396, -0.19010047614574432, -...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_and_embeddings.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0ac7d-585d-4d7b-be4c-1c49864c76c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
