{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5628f14b-f207-42ff-a7a8-119c813bf583",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83eb4ec-24eb-486c-bfab-282f610624dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import sys\n",
    "# sys.path = ['/home/jxm3/research/retrieval/inversion'] + sys.path\n",
    "sys.path = [\n",
    "    p for p in sys.path\n",
    "    if p not in ['/home/jxm3/research/prompting/imodelsX', '/home/jxm3/research/prompting/tree-prompt']\n",
    "]\n",
    "sys.path.append('/home/jxm3/research/retrieval/inversion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278249f9-b243-4549-acf5-4839b2ff15ed",
   "metadata": {},
   "source": [
    "## debugging\n",
    "\n",
    "we trained our first self-correcting model that's decoder-based. generation from it doesn't seem to be working properly, so going to debug in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60660ace-aab9-42b5-be7d-b19f77123ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trainer for analysis – setting --do_eval=1\n",
      "loading alias dpr_nq__msl32_beta from /home/jxm3/research/retrieval/inversion/saves/db66b9c01b644541fedbdcc59c53a285/ebb31d91810c4b62d2b55b5382e8c7ea...\n",
      "Set train_args.dataloader_num_workers = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c000a6deb33746789a1050ddb0f69d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f99025916842938ba40147faabbc14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a400a338244961ad28496cbe290ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff472bc24694bb583b2255968ee4311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output -> The mlbies wase wyst bograge; And the sliths and toms wre\n",
      "================ End trainer sanity check ================\n",
      "Froze 342572160 params from model type <class 'models.inversion.InversionModel'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output -> tomses wry\n",
      "================ End trainer sanity check ================\n"
     ]
    }
   ],
   "source": [
    "# model info:\n",
    "#    https://wandb.ai/jack-morris/emb-correct-1/runs/5b231b25d09f2654d3bc632ded675b12/\n",
    "#             path: saves/645a6cdc14efb137a05d8832920d0f7b\n",
    "\n",
    "import analyze_utils\n",
    "\n",
    "checkpoint_folder = '/home/jxm3/research/retrieval/inversion/saves/645a6cdc14efb137a05d8832920d0f7b'\n",
    "trainer = analyze_utils.load_trainer(checkpoint_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb644b8c-7f2e-439d-b09d-d17fd2a3a085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "trainer.generate()\n",
      "taking first part...\n",
      "\tDecoded output -> The mlbies wase wyst bograge; And the sliths and toms wy málbieses wase the wiest bobrage;And the -lithsand\n",
      "================ End trainer sanity check ================\n"
     ]
    }
   ],
   "source": [
    "trainer.sanity_decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2a2cff-4715-4f79-a66e-75cb44ce2a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating from val:   0%|                                                                                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer.generate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating from val:  50%|███████████████████████████████████████████████████                                                   | 1/2 [00:02<00:02,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking first part...\n",
      "trainer.generate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking first part...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] to the characteristic of the brain, which were relatively smooth, untuktuous on the case for infant suture. Compared the suture,\n",
      "[true] to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "[pred] individual from that Southern Hempisphere To win the Summer Olympic relay silver medal,and was also as part of Australian Shorttrack team, who won gold\n",
      "[true] individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "[pred] the same right as men and  75% agree that they would be protected of discrimination1. Among those other 15%; gay workers be no longer ex\n",
      "[true] the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5283884406089783,\n",
       " 'eval_token_set_precision': 0.5148810598441825,\n",
       " 'eval_token_set_recall': 0.49502385643068364,\n",
       " 'eval_token_set_f1': 0.5036771028008477,\n",
       " 'eval_bleu_score': 4.532495944733702,\n",
       " 'eval_meteor_score': 0.3941053327272833,\n",
       " 'eval_rouge_score': 0.4738296479794146,\n",
       " 'eval_bert_score': 0.8757674533128739,\n",
       " 'eval_emb_cos_sim': 0.8317983150482178,\n",
       " 'eval_runtime': 9.8069,\n",
       " 'eval_samples_per_second': 50.985,\n",
       " 'eval_steps_per_second': 0.204}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(\n",
    "    eval_dataset=trainer.eval_dataset[\"nq\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609edf7e-2718-4f3f-9028-689875f8d771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
