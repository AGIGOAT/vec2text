{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5628f14b-f207-42ff-a7a8-119c813bf583",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83eb4ec-24eb-486c-bfab-282f610624dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import sys\n",
    "# sys.path = ['/home/jxm3/research/retrieval/inversion'] + sys.path\n",
    "sys.path = [\n",
    "    p for p in sys.path\n",
    "    if p not in ['/home/jxm3/research/prompting/imodelsX', '/home/jxm3/research/prompting/tree-prompt']\n",
    "]\n",
    "sys.path.append('/home/jxm3/research/retrieval/inversion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60660ace-aab9-42b5-be7d-b19f77123ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trainer for analysis â€“ setting --do_eval=1\n",
      "loading alias dpr_nq__msl32_beta from /home/jxm3/research/retrieval/inversion/saves/db66b9c01b644541fedbdcc59c53a285/ebb31d91810c4b62d2b55b5382e8c7ea...\n",
      "Set train_args.dataloader_num_workers = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f5391b30054761801feb9a14965533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f57e8328942400ab15a024ea0235c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0730345790148aaa87453ccf8999ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe7ddd5072d47bc945ff241550a8879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output -> The mbbies were the slithe, And it tore all wyrms, and glares\n",
      "================ End trainer sanity check ================\n",
      "Froze 342572160 params from model type <class 'models.inversion.InversionModel'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output -> The mlbies was the wry bograge; And tomse and slithe came thy \n",
      "================ End trainer sanity check ================\n"
     ]
    }
   ],
   "source": [
    "# model info:\n",
    "#    https://wandb.ai/jack-morris/emb-correct-1/runs/a774a9185046f4d67c09937a89553e02?workspace=user-jxmorris12\n",
    "#             path: saves/82b4da0dc13596f747b9f612d22e4d1b\n",
    "\n",
    "import analyze_utils\n",
    "\n",
    "checkpoint_folder = '/home/jxm3/research/retrieval/inversion/saves/82b4da0dc13596f747b9f612d22e4d1b'\n",
    "trainer = analyze_utils.load_trainer(checkpoint_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2a2cff-4715-4f79-a66e-75cb44ce2a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] to that of the character of the sutures of infant skulls, which are relatively smooth and untutuous. In fact, the suture\n",
      "[true] to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "[pred] individual from the Southern Hemisphere to win a Winter Olympic medal, and was also part of the Australian short track relay team that won gold,\n",
      "[true] individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "[pred] the same rights as heterosexuals, and 7% agreed that they should be protected from discrimination. Another 15% disagreed, with 33% working people\n",
      "[true] the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8991079330444336,\n",
       " 'eval_token_set_precision': 0.7434492384730341,\n",
       " 'eval_token_set_recall': 0.7691039899271266,\n",
       " 'eval_token_set_f1': 0.7551881409906644,\n",
       " 'eval_bleu_score': 41.04287373765973,\n",
       " 'eval_meteor_score': 0.6679515165939249,\n",
       " 'eval_rouge_score': 0.7239652090339881,\n",
       " 'eval_bert_score': 0.9336414574384689,\n",
       " 'eval_emb_cos_sim': 0.9378749132156372,\n",
       " 'eval_runtime': 182.7701,\n",
       " 'eval_samples_per_second': 2.736,\n",
       " 'eval_steps_per_second': 0.684}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.args.per_device_eval_batch_size = 4\n",
    "trainer.evaluate(\n",
    "    eval_dataset=trainer.eval_dataset[\"nq\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddefa99-24af-49f8-9e87-3d39ae4ed7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
