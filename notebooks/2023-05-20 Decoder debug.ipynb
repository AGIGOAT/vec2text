{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5628f14b-f207-42ff-a7a8-119c813bf583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c83eb4ec-24eb-486c-bfab-282f610624dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import sys\n",
    "# sys.path = ['/home/jxm3/research/retrieval/inversion'] + sys.path\n",
    "sys.path = [\n",
    "    p for p in sys.path\n",
    "    if p not in ['/home/jxm3/research/prompting/imodelsX', '/home/jxm3/research/prompting/tree-prompt']\n",
    "]\n",
    "sys.path.append('/home/jxm3/research/retrieval/inversion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278249f9-b243-4549-acf5-4839b2ff15ed",
   "metadata": {},
   "source": [
    "## debugging\n",
    "\n",
    "we trained our first self-correcting model that's decoder-based. generation from it doesn't seem to be working properly, so going to debug in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60660ace-aab9-42b5-be7d-b19f77123ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trainer for analysis â€“ setting --do_eval=1\n",
      "loading alias dpr_nq__msl32_beta from /home/jxm3/research/retrieval/inversion/saves/db66b9c01b644541fedbdcc59c53a285/ebb31d91810c4b62d2b55b5382e8c7ea...\n",
      "Set train_args.dataloader_num_workers = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8f1aca6b134bc48df449d937aaab08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9d3e39a870429da061663e7aeb53d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3e5dac7b1a4890a300d2a9886ef844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1916cf8cd0b4024923771587fcca2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output -> The mlbies wase wyst bograge; And the sliths and toms wre\n",
      "================ End trainer sanity check ================\n",
      "Froze 342572160 params from model type <class 'models.inversion.InversionModel'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "trainer generate\n",
      "> \u001b[0;32m/home/jxm3/research/retrieval/inversion/trainers/corrector.py\u001b[0m(177)\u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    175 \u001b[0;31m            \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedder_input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    176 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 177 \u001b[0;31m            \u001b[0mgen_text_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_text_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mgen_text_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    179 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p gen_text_ids[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,    37,     3,    51,     2,    40,  4232,     7,    47,    15,\n",
      "            3,   210,    63,     7,    17,     3, 12247,  4843,   117,   275,\n",
      "            8,     3,     7, 18800,     7,    11,    12,    51,     7,     3,\n",
      "          210,    63,     1,    37,     3,   635,     2,    40,   969,     7,\n",
      "           47,    36,    15,     3, 12124,     7,    17,     5,     3, 12247,\n",
      "        25202,   117,    11,     8,     3,  4411,     7,    11,   304,    51,\n",
      "            7,   130,     3,    63, 32098, 32098], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p self.embedder_tokenizer.decode(gen_text_ids[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<pad> The m<unk>lbies wase wyst bograge; And the sliths and toms wy</s> The mm<unk>lbys was bee whist. bogroar; and the stons and Toms were y<extra_id_1><extra_id_1>'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p self.embedder_tokenizer.decode(gen_text_ids[0][:max_length])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<pad> The m<unk>lbies wase wyst bograge; And the sliths and toms wy</s> The mm<unk>lbys was bee whist. bogroar; and the stons and'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p self.embedder_tokenizer.decode(gen_text_ids[0][max_length:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Toms were y<extra_id_1><extra_id_1>'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDecoded output -> Toms were y\n",
      "================ End trainer sanity check ================\n"
     ]
    }
   ],
   "source": [
    "# model info:\n",
    "#    https://wandb.ai/jack-morris/emb-correct-1/runs/baaadeca9db9d6364d0b0fcf925dd696/\n",
    "#             path: saves/55a40f8fc253ee9dd08283aec6c74a79\n",
    "\n",
    "import analyze_utils\n",
    "\n",
    "checkpoint_folder = '/home/jxm3/research/retrieval/inversion/saves/55a40f8fc253ee9dd08283aec6c74a79'\n",
    "trainer = analyze_utils.load_trainer(checkpoint_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2a2cff-4715-4f79-a66e-75cb44ce2a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/jxm3/research/retrieval/inversion/models/corrector.py\u001b[0m(164)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    162 \u001b[0;31m        )\n",
      "\u001b[0m\u001b[0;32m    163 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 164 \u001b[0;31m        return self.encoder_decoder(\n",
      "\u001b[0m\u001b[0;32m    165 \u001b[0;31m            \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    166 \u001b[0;31m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  labels[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   12,     8,  1848,    13,     8,  2629, 10471,    13,     8, 21995,\n",
      "           84,     6,   114,   273,    13,     8,  9806, 21995,     6,    33,\n",
      "         4352,  3050,    11,    73,    17,   127,    17, 13281,     5,    86,\n",
      "          685,     1,    12,     8,  1848,    13,     8,  2629, 10471,    13,\n",
      "            8, 21995,    84,     6,   114,   273,    13,     8,  9806, 21995,\n",
      "            6,    33,  4352,  3050,    11,    73,    17,   127,    17, 13281,\n",
      "            5,    86,   685,     1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p self.encoder_decoder(inputs_embeds=inputs_embeds,attention_mask=attention_mask,labels=labels).loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5033, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  labels.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 64])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  labels[:, 32:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   12,     8,  1848,  ...,    86,   685,     1],\n",
      "        [  928,    45,     8,  ...,  2051,    31,     1],\n",
      "        [    8,   337,  2166,  ...,    13,   454,     1],\n",
      "        ...,\n",
      "        [   41,  1329,    40,  ...,  1713,   948,     1],\n",
      "        [  276, 18308, 25464,  ...,   406,  5142,     1],\n",
      "        [   47,  2170,    16,  ...,     6,   213,     1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  tlabels = labels.where(torch.arange(64)>=32, labels, -100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TypeError: where() received an invalid combination of arguments - got (Tensor, Tensor, int), but expected one of:\n",
      " * (Tensor condition, Tensor other)\n",
      " * (Tensor condition, Number other)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  tlabels = torch.where(torch.arange(64)>=32, labels, -100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>   tlabels = torch.where(torch.arange(64, device='cuda:0')>=32, labels, -100)\n",
      "ipdb>  tlabels[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,    12,     8,  1848,    13,     8,  2629, 10471,    13,\n",
      "            8, 21995,    84,     6,   114,   273,    13,     8,  9806, 21995,\n",
      "            6,    33,  4352,  3050,    11,    73,    17,   127,    17, 13281,\n",
      "            5,    86,   685,     1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  output = self.encoder_decoder(inputs_embeds=inputs_embeds,attention_mask=attention_mask,labels=labels,)\n",
      "ipdb>  toutput = self.encoder_decoder(inputs_embeds=inputs_embeds,attention_mask=attention_mask,labels=tlabels,)\n",
      "ipdb>  toutput.loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1103, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  output.loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5033, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  tlabels = torch.where(torch.arange(64, device='cuda:0')>=32, labels, 100)\n",
      "ipdb>  self.encoder_decoder(inputs_embeds=inputs_embeds,attention_mask=attention_mask,labels=tlabels,).loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.5762, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(\n",
    "    eval_dataset=trainer.eval_dataset[\"nq\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609edf7e-2718-4f3f-9028-689875f8d771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
