{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a508121-bf9d-4aed-aacb-1cce9ab275b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import sys\n",
    "sys.path = [\n",
    "    p for p in sys.path\n",
    "    if p not in ['/home/jxm3/research/prompting/imodelsX', '/home/jxm3/research/prompting/tree-prompt']\n",
    "]\n",
    "sys.path.append('/home/jxm3/research/retrieval/inversion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85948908-fa3c-495d-9c14-9a60393dcf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading alias gtr_nq__msl32_beta__correct from /home/jxm3/research/retrieval/inversion/saves/47d9c149a8e827d0609abbeefdfd89ac...\n",
      "> checkpoint: /home/jxm3/research/retrieval/inversion/saves/47d9c149a8e827d0609abbeefdfd89ac/checkpoint-558000\n",
      "set dataset to nq\n",
      "loading alias dpr_nq__msl32_beta from /home/jxm3/research/retrieval/inversion/saves/db66b9c01b644541fedbdcc59c53a285/ebb31d91810c4b62d2b55b5382e8c7ea...\n",
      "> checkpoint: /home/jxm3/research/retrieval/inversion/saves/db66b9c01b644541fedbdcc59c53a285/ebb31d91810c4b62d2b55b5382e8c7ea/checkpoint-999744\n",
      "Loading datasets with TOKENIZERS_PARALLELISM = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming keys {'embedding_transform.2.bias', 'embedding_transform.2.weight'} for backward compatibility.\n",
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output shape ->  torch.Size([1, 33])\n",
      "\tDecoded output -> The mlbies wase wyst bograge; And the sliths and toms wre\n",
      "================ End trainer sanity check ================\n",
      "Froze 342572160 params from model type <class 'models.inversion.InversionModel'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming keys {'embedding_transform.2.bias', 'embedding_transform.2.weight'} for backward compatibility.\n",
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output shape ->  torch.Size([1, 33])\n",
      "\tDecoded output -> The slithe and the tobogbes were mly; It wis grabbse tiring\n",
      "================ End trainer sanity check ================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import aliases\n",
    "\n",
    "# inv_trainer = aliases.load_trainer_from_alias(\"openai_msmarco__msl128__100epoch\")\n",
    "corr_experiment, corr_trainer = aliases.load_experiment_and_trainer_from_alias(\"gtr_nq__msl32_beta__correct\")\n",
    "inv_trainer = corr_trainer.inversion_trainer\n",
    "# corr_trainer.precompute_hypotheses()\n",
    "corr_trainer.model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3df908-d91f-493e-9803-b6b3d5853f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] to the character of the sutures of the skull, which, like those of the infant skull, are relatively smooth and untornuous. Indeed\n",
      "[true] to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "[pred] individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "[true] individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "[pred] same rights as straight people, while 15% agreed that they should be protected from workplace discrimination. Additionally, 13% disagreed. 69% of H-\n",
      "[true] the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "{'eval_nq_loss': 0.6404249668121338, 'eval_nq_pred_num_tokens': 31.0, 'eval_nq_true_num_tokens': 32.0, 'eval_nq_token_set_precision': 0.9178558726221202, 'eval_nq_token_set_recall': 0.9255735816074822, 'eval_nq_token_set_f1': 0.921431536071394, 'eval_nq_bleu_score': 75.41253923476056, 'eval_nq_meteor_score': 0.8921194996873874, 'eval_nq_rouge_score': 0.9097580497749944, 'eval_nq_exact_match': 0.414, 'eval_nq_emb_cos_sim': 0.9845502376556396, 'eval_nq_runtime': 19.7843, 'eval_nq_samples_per_second': 25.273, 'eval_nq_steps_per_second': 0.202}\n"
     ]
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 128\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 5\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"nq\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval_nq\",\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a917d248-bf47-466c-ba17-e387222bb3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='159' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 13:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] to the character of the sutures of the skull, which, like those of the infant skull, are relatively smooth and untornuous. Indeed\n",
      "[true] to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "[pred] individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "[true] individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "[pred] the same rights as straight people, while 15% disagreed. Additionally, 13% agreed that they should be protected from workplace discrimination. 69% of H\n",
      "[true] the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "{'eval_nq_loss': 0.640424907207489, 'eval_nq_pred_num_tokens': 31.0, 'eval_nq_true_num_tokens': 32.0, 'eval_nq_token_set_precision': 0.9473560470950129, 'eval_nq_token_set_recall': 0.9545114912185175, 'eval_nq_token_set_f1': 0.9507149227891946, 'eval_nq_bleu_score': 82.99229769499587, 'eval_nq_meteor_score': 0.9308821960693017, 'eval_nq_rouge_score': 0.943450342989768, 'eval_nq_exact_match': 0.568, 'eval_nq_emb_cos_sim': 0.9917903542518616, 'eval_nq_runtime': 226.6175, 'eval_nq_samples_per_second': 2.206, 'eval_nq_steps_per_second': 0.141}\n"
     ]
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 16\n",
    "corr_trainer.sequence_beam_width = 4\n",
    "corr_trainer.num_gen_recursive_steps = 5\n",
    "\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"nq\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval_nq\",\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fde1fb-0892-4bdb-9c15-85042d884cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 8\n",
    "corr_trainer.sequence_beam_width = 4\n",
    "corr_trainer.num_gen_recursive_steps = 50\n",
    "\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"nq\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval_nq\",\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24cb345d-feca-41e7-8b72-0548ad413879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] to the character of the sutures of the skull, which, like those of the infant skull, are relatively smooth and untornuous. Indeed\n",
      "[true] to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "[pred] individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "[true] individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "[pred] the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "[true] the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "{'eval_nq_loss': 0.640424907207489, 'eval_nq_pred_num_tokens': 31.0, 'eval_nq_true_num_tokens': 32.0, 'eval_nq_token_set_precision': 0.9318768045221499, 'eval_nq_token_set_recall': 0.94017112498065, 'eval_nq_token_set_f1': 0.9357483842436927, 'eval_nq_bleu_score': 78.53058521035312, 'eval_nq_meteor_score': 0.9108938577872909, 'eval_nq_rouge_score': 0.9278587870735759, 'eval_nq_exact_match': 0.432, 'eval_nq_emb_cos_sim': 0.9879564046859741, 'eval_nq_runtime': 115.8154, 'eval_nq_samples_per_second': 4.317, 'eval_nq_steps_per_second': 0.276}\n"
     ]
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 16\n",
    "corr_trainer.sequence_beam_width = 1\n",
    "corr_trainer.num_gen_recursive_steps = 5\n",
    "\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 4,\n",
    "    \"num_return_sequences\": 4,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"nq\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval_nq\",\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d75911-e544-4516-8313-d465ed5b741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_trainer.return_best_hypothesis = True\n",
    "corr_trainer.args.per_device_eval_batch_size = 8\n",
    "corr_trainer.sequence_beam_width = 4\n",
    "corr_trainer.num_gen_recursive_steps = 5\n",
    "\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"nq\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval_nq\",\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a350c-e8d2-4224-9e41-01b15b1766df",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 128\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 5\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"nq\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval_nq\",\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152bf1e-43b0-46e6-874f-4e4b304a6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_trainer.return_best_hypothesis = True\n",
    "corr_trainer.args.per_device_eval_batch_size = 64\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 4,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 5\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"nq\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval_nq\",\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4661402-72b3-436c-bda8-4232575100d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_trainer.return_best_hypothesis = True\n",
    "corr_trainer.args.per_device_eval_batch_size = 8\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 32,\n",
    "    \"num_return_sequences\": 32,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 5\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"nq\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval_nq\",\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624e83f5-a932-4d23-97dc-ad79b4edccef",
   "metadata": {},
   "source": [
    "## Testing sequence-level beam width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d70a25-0a8b-416d-8cda-1d1a9eaf8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_trainer.args.per_device_eval_batch_size = 100\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "    \"min_length\": 32, \"max_length\": 32\n",
    "}\n",
    "\n",
    "eval_batch = next(iter(corr_trainer.get_eval_dataloader(eval_dataset=corr_trainer.eval_dataset[\"nq\"])))\n",
    "one_eval_batch = {k: v[31:33] for k,v in eval_batch.items() }\n",
    "one_eval_batch = {k: v.to(corr_trainer.args.device) for k,v in one_eval_batch.items() }\n",
    "\n",
    "print(\n",
    "    corr_trainer.embedder_tokenizer.batch_decode(one_eval_batch[\"embedder_input_ids\"], skip_special_tokens=True)\n",
    ")\n",
    "\n",
    "gen_ids = corr_trainer.generate(\n",
    "    inputs=one_eval_batch,\n",
    "    generation_kwargs=corr_trainer.gen_kwargs,\n",
    "    num_recursive_steps=5,\n",
    "    sequence_beam_width=5,\n",
    ")\n",
    "print(\n",
    "    corr_trainer.embedder_tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a008a875-fe28-4f48-96e0-13d8a3e2ffb8",
   "metadata": {},
   "source": [
    "## Getting trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec2256-04e2-46f9-a65e-bcc8f88a671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = corr_trainer\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "def get_trajectories(inputs: Dict[str, torch.Tensor], num_beams: int = 1, num_rounds: int = 5) -> Dict:\n",
    "    gen_kwargs = copy.copy(trainer.gen_kwargs)\n",
    "    gen_kwargs[\"num_beams\"] = num_beams\n",
    "    frozen_embeddings = trainer.get_frozen_embeddings(\n",
    "        embedder_input_ids=inputs[\"embedder_input_ids\"],\n",
    "        embedder_attention_mask=inputs[\"embedder_attention_mask\"],\n",
    "    )\n",
    "    print(\"input:\", trainer.embedder_tokenizer.decode(inputs[\"input_ids\"][0]))\n",
    "    all_guesses = [trainer.embedder_tokenizer.decode(inputs[\"input_ids\"][0], skip_special_tokens=True)]\n",
    "    embeddings = []\n",
    "    for n in range(num_rounds):\n",
    "        if n == 0:\n",
    "            trainer.inversion_trainer.model.use_frozen_embeddings_as_input = False\n",
    "            hypothesis = trainer.inversion_trainer.generate(inputs=inputs, generation_kwargs=gen_kwargs)\n",
    "        else:\n",
    "            hypothesis = trainer.generate(inputs=inputs, generation_kwargs=gen_kwargs, num_recursive_steps=1)\n",
    "        # queue up next round             \n",
    "        hypothesis_embedding = trainer.embed_generated_hypothesis(input_ids=hypothesis)\n",
    "        inputs[\"frozen_embeddings\"] = frozen_embeddings\n",
    "        inputs[\"hypothesis_input_ids\"] = hypothesis\n",
    "        inputs[\"hypothesis_attention_mask\"] = (hypothesis != trainer.model.encoder_decoder.config.pad_token_id).int()\n",
    "        inputs[\"hypothesis_embedding\"] = hypothesis_embedding\n",
    "        # import pdb; pdb.set_trace()\n",
    "        embeddings.append(hypothesis_embedding.cpu())\n",
    "        dist = torch.nn.CosineSimilarity(dim=1)(hypothesis_embedding, frozen_embeddings).item()\n",
    "        print(f\"round {n+1} ({dist:.3f}):\", trainer.embedder_tokenizer.decode(hypothesis[0], skip_special_tokens=True))\n",
    "        all_guesses.append(trainer.embedder_tokenizer.decode(hypothesis[0], skip_special_tokens=True))\n",
    "    return {\n",
    "        \"true_emb\": frozen_embeddings.cpu(),\n",
    "        \"true_str\": trainer.embedder_tokenizer.decode(inputs[\"input_ids\"][0], skip_special_tokens=True),\n",
    "        \"trajectory_emb\": torch.stack(embeddings), \n",
    "        \"trajectory_str\": all_guesses,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5220e17-bc00-497d-889a-7bc012e5be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_trainer.args.per_device_eval_batch_size = 100\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "\n",
    "eval_batch = next(iter(trainer.get_eval_dataloader(eval_dataset=trainer.eval_dataset[\"nq\"])))\n",
    "\n",
    "data = []\n",
    "for i in range(len(eval_batch[\"input_ids\"])):\n",
    "    one_eval_batch = {k: v[None, i] for k,v in eval_batch.items() }\n",
    "    one_eval_batch = {k: v.to(trainer.args.device) for k,v in one_eval_batch.items() } # put on GPU\n",
    "    trainer.inversion_trainer.model.use_frozen_embeddings_as_input = False\n",
    "    # trainer.embedder_tokenizer.decode(().flatten())\n",
    "    data.append(get_trajectories(inputs=one_eval_batch, num_rounds=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba15d95-041f-4460-9097-a10eb8266ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(data, open(\"trajectories_sl32.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0916d4-1fc8-4c4e-9f37-3ee3a3752866",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).iloc[26][\"trajectory_str\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231aba86-dea8-401a-a65c-79315987239d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
