{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324e1c4e-f125-4d40-b059-d9b6dfc4cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import sys\n",
    "sys.path = [\n",
    "    p for p in sys.path\n",
    "    if p not in ['/home/jxm3/research/prompting/imodelsX', '/home/jxm3/research/prompting/tree-prompt']\n",
    "]\n",
    "sys.path.append('/home/jxm3/research/retrieval/inversion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57524c86-a8ae-41cc-aa09-e51993272db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading alias openai_msmarco__msl128__100epoch__correct from /home/jxm3/research/retrieval/inversion/saves/d6ec9d5838a4ad3daeba636e5378a8a0...\n",
      "> checkpoint: /home/jxm3/research/retrieval/inversion/saves/d6ec9d5838a4ad3daeba636e5378a8a0/checkpoint-384000\n",
      "Corrector encoder noise level 0.001\n",
      "loading alias openai_msmarco__msl128__100epoch from /home/jxm3/research/retrieval/inversion/saves/f9abd65db4c4823264b133816d08612f...\n",
      "Overwriting max sequence length from 128 to 128\n",
      "Overwriting use_less_data from 1000000 to 1000000\n",
      "> checkpoint: /home/jxm3/research/retrieval/inversion/saves/f9abd65db4c4823264b133816d08612f/checkpoint-194000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets with TOKENIZERS_PARALLELISM = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output shape ->  torch.Size([1, 86])\n",
      "\tDecoded output -> And the trolls, trolls, trolls, trolls, trolls, trolls, trolls, trolls, trolls, trolls, trolls, trolls, trolls, trolls, was brilliant, and smooty.\n",
      "================ End trainer sanity check ================\n",
      "Froze 353779584 params from model type <class 'models.inversion.InversionModel'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output shape ->  torch.Size([1, 64])\n",
      "\tDecoded output -> Was brilliant, and witty, And witty, and witty, and witty, and witty, and witty, and witty, witty, witty, witty, witty, witty, witty.\n",
      "================ End trainer sanity check ================\n",
      "Loading hypotheses from path /home/jxm3/research/retrieval/inversion/saves/f9abd65db4c4823264b133816d08612f/9d4a4d4b36da188a6e9dcb9736262823/0ed77465b20070e5_hypotheses.cache\n",
      "Loading hypotheses from path /home/jxm3/research/retrieval/inversion/saves/f9abd65db4c4823264b133816d08612f/9d4a4d4b36da188a6e9dcb9736262823/fa5c492104fd5235_hypotheses.cache\n",
      "Loading hypotheses from path /home/jxm3/research/retrieval/inversion/saves/f9abd65db4c4823264b133816d08612f/9d4a4d4b36da188a6e9dcb9736262823/927a7aa89af4e080_hypotheses.cache\n",
      "Loading hypotheses from path /home/jxm3/research/retrieval/inversion/saves/f9abd65db4c4823264b133816d08612f/9d4a4d4b36da188a6e9dcb9736262823/d405c2908a2abede_hypotheses.cache\n",
      "Loading hypotheses from path /home/jxm3/research/retrieval/inversion/saves/f9abd65db4c4823264b133816d08612f/9d4a4d4b36da188a6e9dcb9736262823/35c1eff11b4e82d2_hypotheses.cache\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import aliases\n",
    "\n",
    "os.environ[\"TOKENIZERS_MULTIPROCESSING\"] = \"True\"\n",
    "\n",
    "# inv_trainer = aliases.load_trainer_from_alias(\"openai_msmarco__msl128__100epoch\")\n",
    "corr_experiment, corr_trainer = aliases.load_experiment_and_trainer_from_alias(\n",
    "    \"openai_msmarco__msl128__100epoch__correct\"\n",
    ")\n",
    "inv_trainer = corr_trainer.inversion_trainer\n",
    "corr_trainer.precompute_hypotheses()\n",
    "corr_trainer.model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd8833f7-52b7-41e0-8bf9-5ff57118d2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] [Submitting Floor Plan: The proposed use permit will require the separate parking space for each existing. drive room and driveway.] The dimensions of the proposed use will be shown on the building dimensions sheet as a complete, symmetrical size.\n",
      "[true] *The use of the driveway as the required parking spaces will require a separate submittal for a Use Permit. [ ] Floor plan (dimensioned): Show overall building size, existing and proposed room locations, existing and. proposed new window(s)/door(s) size/location(s).\n",
      "\n",
      "\n",
      "\n",
      "[pred] Our INSPIRED Seville map is fully illustrated with a map of each street, allowing you to explore the hidden treasures of the city in an intuitive manner. Our Seville map also includes a map of the city's central square, a map of the city's streets and a map of the city's parks and gardens.reyvale, Spain√¢s hidden treasures, and the quaint streets of Seville, are all accessible to anyone with a keen sense of location and a keen sense of direction.\n",
      "[true] Our STREETWISE Seville Map enables you to explore each hidden corner of this enticing destination with a clearly defined map of the city, fully indexed and highlighted with hotels, parks and gardens, and places of interest. An inset of the center of Seville makes even the tiniest of alleyways navigable.rea maps of Cordoba, Grenada and Seville facilitate your entry into these three principal cities via auto, giving you the greatest freedom to experience all that is Southern Spain.\n",
      "\n",
      "\n",
      "\n",
      "[pred] aaa coupons save $ 32 save $ 32 with an average coupon of $ 32 for aaacom aaa is not an affiliate of aacom a united states company that promotes travel and saves money for members aaa offers more than 20 useful coupons and discounts for members of the aacom community including discounts on car insurance auto insurance travel and more\n",
      "[true] aaa coupon codes about aaa save an average of $ 32 with 26 coupon codes deals for aaa com aaa is a not for profit organization that lists the automobile clubs in the united states and offers travel benefits and automobile insurance to its members members review the aaa positively for its convenient travel benefits pricing of services and insurance claim policies shop aaa com show more show less\n",
      "{'eval_test_loss': 1.7535979747772217, 'eval_test_pred_num_tokens': 83.0, 'eval_test_true_num_tokens': 81.77999877929688, 'eval_test_token_set_precision': 0.5408491005235782, 'eval_test_token_set_recall': 0.6095410575667808, 'eval_test_token_set_f1': 0.5688109011285202, 'eval_test_n_ngrams_match_1': 35.03, 'eval_test_n_ngrams_match_2': 14.13, 'eval_test_n_ngrams_match_3': 7.07, 'eval_test_num_true_words': 63.22, 'eval_test_num_pred_words': 63.13, 'eval_test_bleu_score': 17.905276815447916, 'eval_test_meteor_score': 0.44259016982473015, 'eval_test_rouge_score': 0.5616032827872867, 'eval_test_exact_match': 0.01, 'eval_test_emb_cos_sim': 0.9577404856681824, 'eval_test_runtime': 12.8483, 'eval_test_samples_per_second': 7.783, 'eval_test_steps_per_second': 0.078}\n"
     ]
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 128\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 1\n",
    "metrics = corr_trainer.evaluate(\n",
    "    # eval_dataset=corr_trainer.train_dataset.select(range(100)),\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"msmarco\"].select(range(100)),\n",
    "    metric_key_prefix=\"eval_test\",\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed2f66d-17cf-4613-b989-7a5ac4565d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] Examples of Binary Acids. Binary acids begin with the name of the element, such as H2O (Hydrochloric Acid), H3O (Hydrochloric Acid), H2O (Hydrochloric Acid), and H3O (Hydrochloric Acid). These acids are followed by one other element, such as a nonmetal, such as a metal, such as a tetrafluorine or a tetrahydroxide. The two nonmetals are named in pairs, like te\n",
      "[true] Examples: HF, HCl, HBr, HI, H2O, H2S. The names of binary acids begin with hydro-followed by the name of the other element modified to end with-ic (like in hydro chlor ic acid). Binary Acids are one of two classes of acids, the second being the Ternary Acids. The Ternary acids either consist of a hydrogen, oxygen and one other nonmetal element called the oxoacids (like HNO3), or they consist of hydrogen and two other nonmetal elements,\n",
      "\n",
      "\n",
      "\n",
      "[pred] Co:Writer should now be in the beginning of sentences. Co:Writer will send out sentences as you type. You will be able to concentrate on one word at a time. As you type, Co:Writer will give you a cursor to type the words and a sentence.\n",
      "[true] Co:Writer should now be in the foreground. Writing Sentences: You will write sentences one at a time with Co:Writer. As you begin to type a word, Co:Writer offers guesses as to what the word is, based on the letters you typed and other factors.\n",
      "\n",
      "\n",
      "\n",
      "[pred] mundane. Relating to or characteristic of the earth: earthbound, earthen, earthly, earthly world, earthen worlds, earthly man, earthly worlds, earthly worlds, earthly, earthly-manual, earthly.\n",
      "[true] mundane. Relating to or characteristic of the earth or of human life on earth: earthbound, earthen, earthly, earthy, secular, tellurian, telluric, temporal, terrene, terrestrial, worldly.\n",
      "{'eval_test_loss': 1.1519604921340942, 'eval_test_pred_num_tokens': 78.08000183105469, 'eval_test_true_num_tokens': 77.08999633789062, 'eval_test_token_set_precision': 0.6124645294290512, 'eval_test_token_set_recall': 0.7024473863828685, 'eval_test_token_set_f1': 0.6460684918080188, 'eval_test_n_ngrams_match_1': 35.23, 'eval_test_n_ngrams_match_2': 18.43, 'eval_test_n_ngrams_match_3': 11.78, 'eval_test_num_true_words': 58.73, 'eval_test_num_pred_words': 57.19, 'eval_test_bleu_score': 28.28299074945037, 'eval_test_meteor_score': 0.5422510729038869, 'eval_test_rouge_score': 0.6320226459193409, 'eval_test_exact_match': 0.02, 'eval_test_emb_cos_sim': 0.9655460715293884, 'eval_test_runtime': 9.1125, 'eval_test_samples_per_second': 10.974, 'eval_test_steps_per_second': 0.11}\n"
     ]
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 128\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 1\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.train_dataset.select(range(100)),\n",
    "    # eval_dataset=corr_trainer.eval_dataset[\"msmarco\"].select(range(100)),\n",
    "    metric_key_prefix=\"eval_test\",\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53fdee18-6299-4b50-a8e7-ad1fe1124003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import torch\n",
    "train_data_subset = corr_trainer.eval_dataset[\"msmarco\"].select(range(200)).to_dict()\n",
    "# random.shuffle(train_data_subset['frozen_embeddings'])\n",
    "perm = torch.randperm(200)\n",
    "train_data_subset['hypothesis_input_ids'] = [train_data_subset['hypothesis_input_ids'][i] for i in perm]\n",
    "train_data_subset['hypothesis_attention_mask'] = [train_data_subset['hypothesis_attention_mask'][i] for i in perm]\n",
    "random.shuffle(train_data_subset['hypothesis_embedding'])\n",
    "train_data_subset = datasets.Dataset.from_dict(train_data_subset)\n",
    "train_data_subset.set_format(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dce259b-1f53-4071-9c72-7417b2bf6988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] This use of the parking lot will require a separate permit for each additional parking space. [See also: Floor Plan Use of the Parking Lot.]. _____________________________________________________________________________________________________________________________________________________________________________________________________________. The existing subdivision is divided into distinct types of void spaces, called insets, that are affixed to the wall.\n",
      "[true] *The use of the driveway as the required parking spaces will require a separate submittal for a Use Permit. [ ] Floor plan (dimensioned): Show overall building size, existing and proposed room locations, existing and. proposed new window(s)/door(s) size/location(s).\n",
      "\n",
      "\n",
      "\n",
      "[pred] Our SEREA map is illuminated with a hidden map of each street in the city. The map is able to reveal the hidden streets of each city, allowing you to make an accurate exploration of the city's major cities.ourtiland, Seville, and Seville-Antwers are accompanied by a full-size map of the central area, allowing you to make an accurate exploration of the city's major cities.\n",
      "[true] Our STREETWISE Seville Map enables you to explore each hidden corner of this enticing destination with a clearly defined map of the city, fully indexed and highlighted with hotels, parks and gardens, and places of interest. An inset of the center of Seville makes even the tiniest of alleyways navigable.rea maps of Cordoba, Grenada and Seville facilitate your entry into these three principal cities via auto, giving you the greatest freedom to experience all that is Southern Spain.\n",
      "\n",
      "\n",
      "\n",
      "[pred] aaa coupon codes save $ 32 save $ 33 save $ 33 save $ 33 save $ 33 save $ 33 with aaaacom a member of the aaa organization is not an insurance organization typically associated with the aaa membership a member must be 18 years of age or older to apply for benefits not available to them\n",
      "[true] aaa coupon codes about aaa save an average of $ 32 with 26 coupon codes deals for aaa com aaa is a not for profit organization that lists the automobile clubs in the united states and offers travel benefits and automobile insurance to its members members review the aaa positively for its convenient travel benefits pricing of services and insurance claim policies shop aaa com show more show less\n",
      "{'eval_test_loss': 2.116739511489868, 'eval_test_pred_num_tokens': 85.3671875, 'eval_test_true_num_tokens': 80.859375, 'eval_test_token_set_precision': 0.45823241875420256, 'eval_test_token_set_recall': 0.5007070422033969, 'eval_test_token_set_f1': 0.47285406195172075, 'eval_test_n_ngrams_match_1': 29.67, 'eval_test_n_ngrams_match_2': 9.925, 'eval_test_n_ngrams_match_3': 4.23, 'eval_test_num_true_words': 62.17, 'eval_test_num_pred_words': 63.98, 'eval_test_bleu_score': 11.191303887443523, 'eval_test_meteor_score': 0.3526507750707363, 'eval_test_rouge_score': 0.46278574777873216, 'eval_test_exact_match': 0.0, 'eval_test_emb_cos_sim': 0.9295142889022827, 'eval_test_runtime': 11.8669, 'eval_test_samples_per_second': 16.854, 'eval_test_steps_per_second': 0.169}\n"
     ]
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 128\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 1\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=train_data_subset,\n",
    "    # eval_dataset=corr_trainer.eval_dataset[\"msmarco\"].select(range(100)),\n",
    "    metric_key_prefix=\"eval_test\",\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5b9186-f83d-4eff-8ca6-e1b0e687498e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  638,    10, 24965,    49,   225,   230,    36,    16,     8,    21,\n",
       "            15,  9232,     5, 10237,  4892,   324,  2319,    10,   148,    56,\n",
       "          1431, 16513,    80,    44,     3,     9,    97,    28,   638,    10,\n",
       "         24965,    49,     5,   282,    25,  1731,    12,   686,     3,     9,\n",
       "          1448,     6,   638,    10, 24965,    49,   704,  3382,    15,     7,\n",
       "            38,    12,   125,     8,  1448,    19,     6,     3,   390,    30,\n",
       "             8,  5487,    25,   686,    26,    11,   119,  2580,     5,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor([  638,    10, 24965,    49,   225,   230,    36,    16,     8,    21,\n",
       "            15,  9232,     5, 10237,  4892,   324,  2319,    10,   148,    56,\n",
       "          1431, 16513,    80,    44,     3,     9,    97,    28,   638,    10,\n",
       "         24965,    49,     5,   282,    25,  1731,    12,   686,     3,     9,\n",
       "          1448,     6,   638,    10, 24965,    49,   704,  3382,    15,     7,\n",
       "            38,    12,   125,     8,  1448,    19,     6,     3,   390,    30,\n",
       "             8,  5487,    25,   686,    26,    11,   119,  2580,     5,     1]),\n",
       " 'length': tensor(70),\n",
       " 'embedder_input_ids': tensor([  638,    10, 24965,    49,   225,   230,    36,    16,     8,    21,\n",
       "            15,  9232,     5, 10237,  4892,   324,  2319,    10,   148,    56,\n",
       "          1431, 16513,    80,    44,     3,     9,    97,    28,   638,    10,\n",
       "         24965,    49,     5,   282,    25,  1731,    12,   686,     3,     9,\n",
       "          1448,     6,   638,    10, 24965,    49,   704,  3382,    15,     7,\n",
       "            38,    12,   125,     8,  1448,    19,     6,     3,   390,    30,\n",
       "             8,  5487,    25,   686,    26,    11,   119,  2580,     5,     1,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'embedder_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'idx': tensor(1),\n",
       " 'frozen_embeddings': tensor([-0.0079, -0.0096,  0.0122,  ..., -0.0014,  0.0024, -0.0156]),\n",
       " 'hypothesis_embedding': tensor([-0.0096, -0.0196,  0.0038,  ..., -0.0042, -0.0024, -0.0035]),\n",
       " 'hypothesis_input_ids': tensor([    0,   638,    10,  8733,    52,   225,   230,    36,    16,     8,\n",
       "           638,    10,  8733,    52,  1726,     5,   282,    25,   686,     6,\n",
       "           638,    10,  8733,    52,    56,  9005,    25,    12,   474,    39,\n",
       "          1234,    16,     3,     9,  7142,     6,    11,    25,    56,    36,\n",
       "           787,     8,  1004,    12,   686,     8,  1234,    16,     3,     9,\n",
       "          7142,    28,    80,    42,    72,    13,     8,   576,    18, 12756,\n",
       "            31,     7,  6165,     7,     5]),\n",
       " 'hypothesis_attention_mask': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_trainer.train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6811db97-bcc1-413a-9264-0aefd6cd0b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 1429,   634,   169,    13,     8, 16860,    38,     8,   831,  3078,\n",
       "          4856,    56,  1457,     3,     9,  2450,  4237,  1947,    21,     3,\n",
       "             9,  2048,  1915,  1538,     5,   784,     3,   908, 12324,   515,\n",
       "            41, 31987,    15,    26,    61,    10,  3111,  1879,   740,   812,\n",
       "             6,  1895,    11,  4382,   562,  3248,     6,  1895,    11,     5,\n",
       "          4382,   126,  2034,   599,     7,    61,    87, 11968,   599,     7,\n",
       "            61,   812,    87, 14836,   599,     7,   137,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor([ 1429,   634,   169,    13,     8, 16860,    38,     8,   831,  3078,\n",
       "          4856,    56,  1457,     3,     9,  2450,  4237,  1947,    21,     3,\n",
       "             9,  2048,  1915,  1538,     5,   784,     3,   908, 12324,   515,\n",
       "            41, 31987,    15,    26,    61,    10,  3111,  1879,   740,   812,\n",
       "             6,  1895,    11,  4382,   562,  3248,     6,  1895,    11,     5,\n",
       "          4382,   126,  2034,   599,     7,    61,    87, 11968,   599,     7,\n",
       "            61,   812,    87, 14836,   599,     7,   137,     1]),\n",
       " 'length': tensor(68),\n",
       " 'embedder_input_ids': tensor([ 1429,   634,   169,    13,     8, 16860,    38,     8,   831,  3078,\n",
       "          4856,    56,  1457,     3,     9,  2450,  4237,  1947,    21,     3,\n",
       "             9,  2048,  1915,  1538,     5,   784,     3,   908, 12324,   515,\n",
       "            41, 31987,    15,    26,    61,    10,  3111,  1879,   740,   812,\n",
       "             6,  1895,    11,  4382,   562,  3248,     6,  1895,    11,     5,\n",
       "          4382,   126,  2034,   599,     7,    61,    87, 11968,   599,     7,\n",
       "            61,   812,    87, 14836,   599,     7,   137,     1,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'embedder_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'frozen_embeddings': tensor([ 0.0095,  0.0049, -0.0049,  ..., -0.0062, -0.0009, -0.0482]),\n",
       " 'hypothesis_embedding': tensor([ 0.0179,  0.0114, -0.0038,  ..., -0.0028, -0.0188, -0.0358]),\n",
       " 'hypothesis_input_ids': tensor([    0,  1429,   634,  3078,   418,    56,  1457,     8,   169,    13,\n",
       "             3,     9,  2450,  3078,   628,    21,     8,  4382,   169,    13,\n",
       "             8,   740,     5,   784,   308,    23, 20066, 12324,  2926,    10,\n",
       "          2048,    13,  1895,  1501,   515,   628,     6,  8393,     6,    11,\n",
       "            87,   127,  3078,   628,    56,    36,  7972,    30,     8,  5720,\n",
       "             5,     3,    87, 25252,  1538,  1222,  8495,     7,    21,   284,\n",
       "           126,  3078,   628,     5]),\n",
       " 'hypothesis_attention_mask': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_trainer.eval_dataset['msmarco'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa819dc7-e8fb-4b22-9149-66a7f05155b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.keys() <= d1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "220f2484-1391-441b-88a0-cf2aceb19b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for k in d2.keys():\n",
    "    print((d1[k] == d1[k]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7604254a-efdf-43f5-9bcc-77c6667848ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {k: v[None].to(corr_trainer.args.device) for k,v in d1.items()}\n",
    "try:\n",
    "    frozen_embeddings1 = inputs[\"frozen_embeddings\"]\n",
    "    ################################################################################\n",
    "    # # print(\"temp: starting from best hypothesis\")\n",
    "    # hypothesis_input_ids = inputs[\"best_hypothesis_input_ids\"]\n",
    "    # hypothesis_embedding = inputs[\"best_hypothesis_embedding\"]\n",
    "    # hypothesis_attention_mask = (hypothesis_input_ids != self.model.encoder_decoder.config.pad_token_id).int()\n",
    "    ################################################################################\n",
    "    hypothesis_input_ids1 = inputs[\"hypothesis_input_ids\"]\n",
    "    hypothesis_attention_mask1 = inputs[\"hypothesis_attention_mask\"]\n",
    "    hypothesis_embedding1 = inputs[\"hypothesis_embedding\"]\n",
    "    ################################################################################\n",
    "except KeyError:\n",
    "    (\n",
    "        frozen_embeddings1,\n",
    "        hypothesis_input_ids1,\n",
    "        hypothesis_attention_mask1,\n",
    "        hypothesis_embedding1,\n",
    "    ) = corr_trainer_no_precompute._get_hypothesis_uncached(inputs=inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cfbac2a9-b2dc-4710-bddc-f4e1a127cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {k: v[None].to(corr_trainer.args.device) for k,v in d2.items()}\n",
    "try:\n",
    "    frozen_embeddings2 = inputs[\"frozen_embeddings\"]\n",
    "    ################################################################################\n",
    "    # # print(\"temp: starting from best hypothesis\")\n",
    "    # hypothesis_input_ids = inputs[\"best_hypothesis_input_ids\"]\n",
    "    # hypothesis_embedding = inputs[\"best_hypothesis_embedding\"]\n",
    "    # hypothesis_attention_mask = (hypothesis_input_ids != self.model.encoder_decoder.config.pad_token_id).int()\n",
    "    ################################################################################\n",
    "    hypothesis_input_ids2 = inputs[\"hypothesis_input_ids\"]\n",
    "    hypothesis_attention_mask2 = inputs[\"hypothesis_attention_mask\"]\n",
    "    hypothesis_embedding2 = inputs[\"hypothesis_embedding\"]\n",
    "    ################################################################################\n",
    "except KeyError:\n",
    "    (\n",
    "        frozen_embeddings2,\n",
    "        hypothesis_input_ids2,\n",
    "        hypothesis_attention_mask2,\n",
    "        hypothesis_embedding2,\n",
    "    ) = corr_trainer_not_precomputed._get_hypothesis_uncached(inputs=inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56544bc0-be08-41aa-b0c7-43a5fde13e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(frozen_embeddings1 == frozen_embeddings2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f310d8a5-9d88-47fc-a4e2-169203d37be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False, device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hypothesis_embedding1 == hypothesis_embedding2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4b1cda1-4422-4254-bd37-3b14a3ec74e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 19119,    13,     3, 19990,   447, 18802,     7,     5, 17239,\n",
       "           524,   322,   447, 15215,  1731,    28,     8,   564,    13,     8,\n",
       "             3,    23,  4554, 12771,     6,   224,    38,     3,     9,   835,\n",
       "          1162,    41,   566,   357,   667,   201,     3,     9,   835,  1162,\n",
       "            41,   566,   357,   667,   201,    42,     3,     9,   835,  1162,\n",
       "            41,   566,   357,   667,   137, 17239,   729,   447, 15215,    33,\n",
       "          2348,    57,   192,   119,     3,    23,  4554, 18042,     6,   224,\n",
       "            38,     3,     9,   835,  1162,    41,   566,   357,   667,   201,\n",
       "            11,     3,     9,   835,  1162,    41,   566,   357,   667,   137,\n",
       "         17239,   729,   447, 15215,    33,    80,    13,     8,   386,  2287,\n",
       "            13,     3,    23,  4554, 18042,     5,   204,  5388,    18,  3493,\n",
       "          5405,     6,   224,    38,     3,     9,     3,  3828,  5255,     6,\n",
       "            33,   718, 14865,     3,    23,  4554, 15215]], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis_input_ids1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4a5c515-5f96-4d62-a3fb-2373865c9b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 19119,    13, 18802,   447, 18802,     7,   560,     3, 17097,\n",
       "             6,   454,   357,   667,     6,   454,   357,   667,     6,    11,\n",
       "           454,   357,   667,     5, 17239,   729,   447, 18802,     7,  1731,\n",
       "            28,     8,   564,    13,     8,     3,    23,  4554, 12771,    41,\n",
       "           566,    18,    61,  2348,    57,     8,   564,    13,     8,     3,\n",
       "            23,  4554, 12771,    41,   566,    18,   137, 17239,   729,   447,\n",
       "         15215,    33,    80,    13,   192,  2287,    13,     3,    23,  4554,\n",
       "         18042,     6,     8,   119,   192,   271,     3, 15979, 15215,    41,\n",
       "           566,    18,    61,    11,     3, 15979, 15215,    41,   279,    18,\n",
       "           137,     3,  8739,     3,     9,     3,    17,    15,  1313,    88,\n",
       "            26,  4900,  3562,     6,     3,     9,     3, 15979,  3562,    19,\n",
       "             3,     9,     3,    17,    15,  1313,    88,    26,  4900, 12771,\n",
       "            28,     3,     9,     3,    17,    15,  1313,    88]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis_input_ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd996289-ce95-48e4-b874-bff25a056e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': False,\n",
       " 'num_beams': 1,\n",
       " 'do_sample': False,\n",
       " 'no_repeat_ngram_size': 0}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_trainer.gen_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc4f9658-ef06-409c-898c-e1ed1a859629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 19119,    13, 18802,   447, 18802,     7,   560,     3, 17097,\n",
       "             6,   454,   357,   667,     6,   454,   357,   667,     6,    11,\n",
       "           454,   357,   667,     5, 17239,   729,   447, 18802,     7,  1731,\n",
       "            28,     8,   564,    13,     8,     3,    23,  4554, 12771,    41,\n",
       "           566,    18,    61,  2348,    57,     8,   564,    13,     8,     3,\n",
       "            23,  4554, 12771,    41,   566,    18,   137, 17239,   729,   447,\n",
       "         15215,    33,    80,    13,   192,  2287,    13,     3,    23,  4554,\n",
       "         18042,     6,     8,   119,   192,   271,     3, 15979, 15215,    41,\n",
       "           566,    18,    61,    11,     3, 15979, 15215,    41,   279,    18,\n",
       "           137,     3,  8739,     3,     9,     3,    17,    15,  1313,    88,\n",
       "            26,  4900,  3562,     6,     3,     9,     3, 15979,  3562,    19,\n",
       "             3,     9,     3,    17,    15,  1313,    88,    26,  4900, 12771,\n",
       "            28,     3,     9,     3,    17,    15,  1313,    88,     1]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_kwargs = {\n",
    "    'early_stopping': False,\n",
    "    'num_beams': 1,\n",
    "    'do_sample': False,\n",
    "    'no_repeat_ngram_size': 0,\n",
    "    'min_length': 1,\n",
    "    'max_length': 129,\n",
    "}\n",
    "corr_trainer.inversion_trainer.model.generate(inputs=inputs, generation_kwargs=gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc7231-5aac-44e6-9d6d-d1b000a9353a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
