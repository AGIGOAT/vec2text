{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2baf7e-4ffc-4aff-86a7-332c7a62eaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import sys\n",
    "sys.path = [\n",
    "    p for p in sys.path\n",
    "    if p not in ['/home/jxm3/research/prompting/imodelsX', '/home/jxm3/research/prompting/tree-prompt']\n",
    "]\n",
    "sys.path.append('/home/jxm3/research/retrieval/inversion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7761170c-7dcb-403a-a930-d798477b9990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading alias openai_msmarco__msl32__100epoch__correct from /home/jxm3/research/retrieval/inversion/saves/7758f43e621db8ee718306f31139e3b0...\n",
      "> checkpoint: /home/jxm3/research/retrieval/inversion/saves/7758f43e621db8ee718306f31139e3b0/checkpoint-292000\n",
      "Corrector encoder noise level 0.0001\n",
      "loading alias openai_msmarco__msl32__100epoch from /home/jxm3/research/retrieval/inversion/saves/61becf9bb1d627272cd1923ac4871e73...\n",
      "Overwriting max sequence length from 32 to 32\n",
      "Overwriting use_less_data from 5000000 to 5000000\n",
      "> checkpoint: /home/jxm3/research/retrieval/inversion/saves/61becf9bb1d627272cd1923ac4871e73/checkpoint-256000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets with TOKENIZERS_PARALLELISM = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output shape ->  torch.Size([1, 33])\n",
      "\tDecoded output -> And the giggling, giggling, and giggling, smoted torbies, was good!\n",
      "================ End trainer sanity check ================\n",
      "Froze 353779584 params from model type <class 'models.inversion.InversionModel'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jxm3/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output shape ->  torch.Size([1, 33])\n",
      "\tDecoded output -> And the twigs was so good, and muddled, and sliths, and swash-sing fool.\n",
      "================ End trainer sanity check ================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import aliases\n",
    "\n",
    "# inv_trainer = aliases.load_trainer_from_alias(\"openai_msmarco__msl128__100epoch\")\n",
    "corr_experiment, corr_trainer = aliases.load_experiment_and_trainer_from_alias(\"openai_msmarco__msl32__100epoch__correct\")\n",
    "inv_trainer = corr_trainer.inversion_trainer\n",
    "# corr_trainer.precompute_hypotheses()\n",
    "corr_trainer.model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de411f46-d532-4897-9997-b6f717423698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000004826bfed60000166d'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000403f539920000166e'\n",
      "generating from val: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.29it/s]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000005a0f4970c0000166f'\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000005031c218700001670'\n",
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] *The use of the floor space will require a separate parking permit with a separate parking permit. The Floor Plan Subdivision Use Request (\n",
      "[true] *The use of the driveway as the required parking spaces will require a separate submittal for a Use Permit. [ ] Floor plan (\n",
      "\n",
      "\n",
      "\n",
      "[pred] With this SEVIERA map you'll discover a hidden hidden spot in each of our enticing streets, highlighting your hidden interest in\n",
      "[true] Our STREETWISE Seville Map enables you to explore each hidden corner of this enticing destination with a clearly defined map of\n",
      "\n",
      "\n",
      "\n",
      "[pred] aa coupons from 32 aaa coupons with average price of $ 36 save an average of $ 32 save an average of $ 32 save on\n",
      "[true] aaa coupon codes about aaa save an average of $ 32 with 26 coupon codes deals for aaa com a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_msmarco_loss': 1.2146152257919312,\n",
       " 'eval_msmarco_accuracy': 0.701625,\n",
       " 'eval_msmarco_pred_num_tokens': 30.84375,\n",
       " 'eval_msmarco_true_num_tokens': 31.828125,\n",
       " 'eval_msmarco_token_set_precision': 0.5983225770773084,\n",
       " 'eval_msmarco_token_set_recall': 0.6369261488122231,\n",
       " 'eval_msmarco_token_set_f1': 0.6143664055568618,\n",
       " 'eval_msmarco_n_ngrams_match_1': 14.45,\n",
       " 'eval_msmarco_n_ngrams_match_2': 7.198,\n",
       " 'eval_msmarco_n_ngrams_match_3': 4.298,\n",
       " 'eval_msmarco_num_true_words': 24.298,\n",
       " 'eval_msmarco_num_pred_words': 24.374,\n",
       " 'eval_msmarco_bleu_score': 26.191826433010338,\n",
       " 'eval_msmarco_meteor_score': 0.5326615692385879,\n",
       " 'eval_msmarco_rouge_score': 0.6033023599344638,\n",
       " 'eval_msmarco_exact_match': 0.016,\n",
       " 'eval_msmarco_emb_cos_sim': 0.9365552663803101,\n",
       " 'eval_msmarco_perplexity': 3.3689975115480784,\n",
       " 'eval_msmarco_runtime': 10.2995,\n",
       " 'eval_msmarco_samples_per_second': 48.546,\n",
       " 'eval_msmarco_steps_per_second': 0.194}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = inv_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"msmarco\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval_msmarco\",\n",
    ")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440c4dec-be02-4025-b517-d279bb2b68eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 3:46:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000007824e127b00001673'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000068325e67f00001671'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000006037010a000001672'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000070303b64b00001674'\n",
      "generating from val: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:13<00:00,  3.21s/it]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000901070f5000001676'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000080acd25e100001677'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000008828c27d100001675'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000982ee7d1b00001678'\n",
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] [The use of the driveway will require a separate parking permit with a separate permit required.] Subdivision Plan. Floor use ((\n",
      "[true] *The use of the driveway as the required parking spaces will require a separate submittal for a Use Permit. [ ] Floor plan (\n",
      "\n",
      "\n",
      "\n",
      "[pred] Our SEVILIZ£o Street Map enables you to explore each of your hidden delights with a clearly entangled street map of\n",
      "[true] Our STREETWISE Seville Map enables you to explore each hidden corner of this enticing destination with a clearly defined map of\n",
      "\n",
      "\n",
      "\n",
      "[pred] aaa coupons with 32 codes save an average of $ 26 aaaa coupons com aaa coupons about aa\n",
      "[true] aaa coupon codes about aaa save an average of $ 32 with 26 coupon codes deals for aaa com a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7599747180938721,\n",
       " 'eval_pred_num_tokens': 30.859375,\n",
       " 'eval_true_num_tokens': 31.828125,\n",
       " 'eval_token_set_precision': 0.7591905194388956,\n",
       " 'eval_token_set_recall': 0.7819638886949989,\n",
       " 'eval_token_set_f1': 0.7691521087364407,\n",
       " 'eval_n_ngrams_match_1': 18.258,\n",
       " 'eval_n_ngrams_match_2': 11.532,\n",
       " 'eval_n_ngrams_match_3': 8.016,\n",
       " 'eval_num_true_words': 24.298,\n",
       " 'eval_num_pred_words': 24.208,\n",
       " 'eval_bleu_score': 44.13214374618446,\n",
       " 'eval_meteor_score': 0.7135751045374663,\n",
       " 'eval_rouge_score': 0.7590607835102718,\n",
       " 'eval_exact_match': 0.052,\n",
       " 'eval_emb_cos_sim': 0.9649856686592102,\n",
       " 'eval_runtime': 26.7149,\n",
       " 'eval_samples_per_second': 18.716,\n",
       " 'eval_steps_per_second': 0.15}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 128\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 1\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"msmarco\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval\",\n",
    ")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0daafe0f-0d8a-4714-9099-75a9ca9ccebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000b01efd29a0000167c'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000a890794b80000167b'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000a0103a96500001679'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000b81c6689a0000167a'\n",
      "generating from val: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [02:28<00:00, 36.78s/it]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000d83c12d970000167f'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000d03ff0ac20000167d'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000c04810c2a0000167e'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000c80680f1b00001680'\n",
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] *The use of a separate driveway as parking space will require the submission of a Use Permit. [Submitted] The floor plan (\n",
      "[true] *The use of the driveway as the required parking spaces will require a separate submittal for a Use Permit. [ ] Floor plan (\n",
      "\n",
      "\n",
      "\n",
      "[pred] Our SEVILLE STREETWIDE MAP enables you to explore each hidden enticing destination of this with clearly defined maps of\n",
      "[true] Our STREETWISE Seville Map enables you to explore each hidden corner of this enticing destination with a clearly defined map of\n",
      "\n",
      "\n",
      "\n",
      "[pred] aaa com coupons with 32 codes save an average of $ 26 aaa com coupons about aaa aa\n",
      "[true] aaa coupon codes about aaa save an average of $ 32 with 26 coupon codes deals for aaa com a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7600694894790649,\n",
       " 'eval_pred_num_tokens': 30.8671875,\n",
       " 'eval_true_num_tokens': 31.828125,\n",
       " 'eval_token_set_precision': 0.8646483681596072,\n",
       " 'eval_token_set_recall': 0.8766082648427984,\n",
       " 'eval_token_set_f1': 0.869810156365364,\n",
       " 'eval_n_ngrams_match_1': 20.91,\n",
       " 'eval_n_ngrams_match_2': 15.38,\n",
       " 'eval_n_ngrams_match_3': 12.182,\n",
       " 'eval_num_true_words': 24.298,\n",
       " 'eval_num_pred_words': 24.278,\n",
       " 'eval_bleu_score': 61.87097094667961,\n",
       " 'eval_meteor_score': 0.8373391430843045,\n",
       " 'eval_rouge_score': 0.864754553435346,\n",
       " 'eval_exact_match': 0.15,\n",
       " 'eval_emb_cos_sim': 0.9762566685676575,\n",
       " 'eval_runtime': 160.5408,\n",
       " 'eval_samples_per_second': 3.114,\n",
       " 'eval_steps_per_second': 0.025}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 128\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 20\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"msmarco\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval\",\n",
    ")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6947830b-75c1-46f9-bbf9-47af841c51ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000f01fa800600001682'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000f81974f9500001683'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000e019fe9f800001684'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000e8397ddb500001681'\n",
      "generating from val: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [06:47<00:00, 95.14s/it]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000000089812c00001687'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000001077420a800001685'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000001005b7426300001686'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000000876abe5300001688'\n",
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] *The use of a separate driveway as parking space will require the submission of a Use Permit. [Submitted] The floor plan (\n",
      "[true] *The use of the driveway as the required parking spaces will require a separate submittal for a Use Permit. [ ] Floor plan (\n",
      "\n",
      "\n",
      "\n",
      "[pred] Our SEVILLE STREETWIDE MAP enables you to explore each hidden enticing destination of this with clearly defined maps of\n",
      "[true] Our STREETWISE Seville Map enables you to explore each hidden corner of this enticing destination with a clearly defined map of\n",
      "\n",
      "\n",
      "\n",
      "[pred] aaa com coupons with 32 codes save an average of $ 26 aaa com coupons about aaa aa\n",
      "[true] aaa coupon codes about aaa save an average of $ 32 with 26 coupon codes deals for aaa com a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7600764036178589,\n",
       " 'eval_pred_num_tokens': 30.875,\n",
       " 'eval_true_num_tokens': 31.828125,\n",
       " 'eval_token_set_precision': 0.8644315474568165,\n",
       " 'eval_token_set_recall': 0.8757586156882907,\n",
       " 'eval_token_set_f1': 0.8692423865164676,\n",
       " 'eval_n_ngrams_match_1': 20.92,\n",
       " 'eval_n_ngrams_match_2': 15.494,\n",
       " 'eval_n_ngrams_match_3': 12.306,\n",
       " 'eval_num_true_words': 24.298,\n",
       " 'eval_num_pred_words': 24.256,\n",
       " 'eval_bleu_score': 62.3226455985159,\n",
       " 'eval_meteor_score': 0.8407279564411856,\n",
       " 'eval_rouge_score': 0.8666497699846307,\n",
       " 'eval_exact_match': 0.148,\n",
       " 'eval_emb_cos_sim': 0.976926863193512,\n",
       " 'eval_runtime': 422.7887,\n",
       " 'eval_samples_per_second': 1.183,\n",
       " 'eval_steps_per_second': 0.009}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 128\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 50\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"msmarco\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval\",\n",
    ")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d73dc84-0124-4dad-b882-cb891da134b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 28:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000c80680f21000016c6'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000b01efd29f000016c5'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000c04810c31000016c8'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000b81c7e8a2000016c7'\n",
      "generating from val:   0%|                                                                                                                                | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 // scores = [0.9583866596221924, 0.9565423130989075, 0.9811453819274902, 0.9539602994918823, 0.9502842426300049, 0.9979091882705688, 0.9778316020965576, 0.9708535671234131, 0.9987426996231079, 0.9788764715194702, 0.9858259558677673, 0.9718614816665649, 0.97817462682724, 0.9870227575302124, 0.9928306341171265, 0.9814497232437134]\n",
      "step 1 // scores = [0.9821966886520386, 0.983578085899353, 0.9831918478012085, 0.988082230091095, 0.9746666550636292, 1.0000001192092896, 0.9859825372695923, 0.9996954798698425, 1.0, 0.9893333911895752, 0.9871928691864014, 0.9783405065536499, 0.9867512583732605, 0.9927146434783936, 1.0000001192092896, 0.9913099408149719]\n",
      "step 2 // scores = [0.9872118234634399, 1.0000001192092896, 0.9831879734992981, 0.9988222122192383, 0.9722269773483276, 0.9999974966049194, 0.9909223318099976, 1.0, 1.0, 0.9937753677368164, 0.9878878593444824, 0.9827483892440796, 0.9874004125595093, 0.9942857623100281, 1.0000001192092896, 0.9964807033538818]\n",
      "step 3 // scores = [0.9904642701148987, 1.0000001192092896, 0.984053909778595, 0.9990241527557373, 0.9759511947631836, 1.0000001192092896, 0.9919531941413879, 1.0, 1.0, 0.9999971389770508, 0.9899872541427612, 0.9860715866088867, 0.9882776737213135, 0.9961085319519043, 1.0000001192092896, 0.9979419708251953]\n",
      "step 4 // scores = [0.9902992844581604, 1.0000001192092896, 0.984053909778595, 1.0, 0.9730832576751709, 1.0000001192092896, 0.9922821521759033, 1.0, 1.0, 0.9999961256980896, 0.9900641441345215, 0.9860630631446838, 0.9882776737213135, 0.9963564872741699, 1.0000001192092896, 0.9999902248382568]\n",
      "step 5 // scores = [0.9906721711158752, 1.0000001192092896, 0.9840836524963379, 1.0, 0.9731556177139282, 0.9999980926513672, 0.9924904704093933, 1.0, 0.9999988079071045, 0.999997615814209, 0.990042507648468, 0.9888860583305359, 0.9882883429527283, 0.9967564344406128, 1.0000001192092896, 0.9999902248382568]\n",
      "step 6 // scores = [0.9907037019729614, 0.9999973177909851, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.994964599609375, 1.0, 1.0, 0.9999980926513672, 0.990042507648468, 0.988947868347168, 0.9882776737213135, 0.9967564344406128, 1.0000001192092896, 1.0]\n",
      "step 7 // scores = [0.9907580018043518, 1.0000001192092896, 0.984053909778595, 0.9994629621505737, 0.9733999967575073, 1.0000001192092896, 0.994964599609375, 1.0, 1.0, 0.9999971389770508, 0.9901243448257446, 0.9889696836471558, 0.9882883429527283, 0.9967564344406128, 1.0000001192092896, 1.0]\n",
      "step 8 // scores = [0.9907580018043518, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9951960444450378, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9889380931854248, 0.9882776737213135, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 9 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9951960444450378, 1.0, 1.0, 0.9999980926513672, 0.9900641441345215, 0.9889380931854248, 0.9882776737213135, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 10 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 0.9999974966049194, 0.9954445362091064, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9889380931854248, 0.9882776737213135, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 11 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 0.9994629621505737, 0.9733999967575073, 1.0000001192092896, 0.995468020439148, 1.0, 1.0, 1.0, 0.990042507648468, 0.9889380931854248, 0.9882776737213135, 0.9980506896972656, 1.0000001192092896, 1.0]\n",
      "step 12 // scores = [0.9907580018043518, 1.0000001192092896, 0.984053909778595, 1.0, 0.9734113812446594, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 0.9999971389770508, 0.9900641441345215, 0.9889380931854248, 0.9882883429527283, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 13 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 1.0, 0.990042507648468, 0.9889380931854248, 0.9882883429527283, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 14 // scores = [0.9907037019729614, 1.0000001192092896, 0.9840905666351318, 0.9994671940803528, 0.9735727906227112, 0.9999979734420776, 0.9954445362091064, 1.0, 1.0, 1.0, 0.9901243448257446, 0.9889380931854248, 0.9882776737213135, 0.9980359673500061, 0.9999979734420776, 1.0]\n",
      "step 15 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 0.9999980926513672, 0.9900641441345215, 0.9889380931854248, 0.9882776737213135, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 16 // scores = [0.9907037019729614, 1.0000001192092896, 0.9840836524963379, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 0.9999971389770508, 0.9900641441345215, 0.9889380931854248, 0.9882776737213135, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 17 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9734113812446594, 1.0000001192092896, 0.9954445362091064, 0.9999992251396179, 1.0, 0.9999971389770508, 0.990042507648468, 0.9889380931854248, 0.9882776737213135, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 18 // scores = [0.9907037019729614, 1.0000001192092896, 0.9840836524963379, 0.999996542930603, 0.973572850227356, 0.9999977946281433, 0.9954445362091064, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9889876246452332, 0.9882776737213135, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 19 // scores = [0.9907182455062866, 0.9999973177909851, 0.984053909778595, 1.0, 0.9734444618225098, 1.0000001192092896, 0.9954283833503723, 0.999998927116394, 1.0, 1.0, 0.9900641441345215, 0.9888860583305359, 0.9882776737213135, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 20 // scores = [0.9907037019729614, 1.0000001192092896, 0.984018087387085, 1.0, 0.973572850227356, 1.0000001192092896, 0.9954445362091064, 1.0, 0.9999990463256836, 0.9999961256980896, 0.9900641441345215, 0.988947868347168, 0.9883018732070923, 0.9980680346488953, 1.0000001192092896, 0.9999977350234985]\n",
      "step 21 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954624176025391, 1.0, 1.0, 0.9999980926513672, 0.9900641441345215, 0.9889696836471558, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 22 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9734113812446594, 1.0000001192092896, 0.995468020439148, 0.9999986886978149, 1.0, 0.9999980926513672, 0.9900641441345215, 0.988947868347168, 0.9893577694892883, 0.9980581998825073, 0.9999983310699463, 0.9999983906745911]\n",
      "step 23 // scores = [0.9906861186027527, 0.9999963641166687, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 0.9999971389770508, 0.990042507648468, 0.988947868347168, 0.9893577694892883, 0.9980506896972656, 1.0000001192092896, 1.0]\n",
      "step 24 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9735351204872131, 0.9999973773956299, 0.9954445362091064, 1.0, 0.9999986290931702, 0.9999968409538269, 0.9900641441345215, 0.9889380931854248, 0.9893496036529541, 0.9980731010437012, 1.0000001192092896, 1.0]\n",
      "step 25 // scores = [0.9907037019729614, 1.0000001192092896, 0.984018087387085, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954208135604858, 0.9999960660934448, 1.0, 1.0, 0.990017831325531, 0.9889380931854248, 0.9893593788146973, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 26 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 1.0, 0.990042507648468, 0.9889380931854248, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 27 // scores = [0.9907037019729614, 0.9999973177909851, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954610466957092, 1.0, 1.0, 1.0, 0.990017831325531, 0.9889696836471558, 0.9893858432769775, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 28 // scores = [0.9907037019729614, 1.0000001192092896, 0.9841270446777344, 0.9994629621505737, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 1.0, 0.9900339841842651, 0.9889696836471558, 0.9893577694892883, 0.9980435967445374, 1.0000001192092896, 1.0]\n",
      "step 29 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 0.9999980926513672, 0.990017831325531, 0.9889380931854248, 0.9893858432769775, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 30 // scores = [0.9906800985336304, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 0.9999977946281433, 0.9954445362091064, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9889380931854248, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 31 // scores = [0.9907182455062866, 1.0000001192092896, 0.984053909778595, 1.0, 0.9734113812446594, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9889380931854248, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 32 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954665899276733, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9889380931854248, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 33 // scores = [0.9907037019729614, 1.0000001192092896, 0.9841270446777344, 0.9994629621505737, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 0.9999971389770508, 0.9901243448257446, 0.9889380931854248, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 34 // scores = [0.9906973242759705, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954624176025391, 1.0, 1.0, 0.9999980926513672, 0.990017831325531, 0.9888860583305359, 0.9893577694892883, 0.9980506896972656, 1.0000001192092896, 0.9999902248382568]\n",
      "step 35 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954440593719482, 1.0, 1.0, 1.0, 0.9900641441345215, 0.988947868347168, 0.9893500804901123, 0.9980581998825073, 1.0000001192092896, 0.9999902248382568]\n",
      "step 36 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 0.9999980926513672, 0.9900641441345215, 0.9889125823974609, 0.9893577694892883, 0.9980506896972656, 0.9999979138374329, 1.0]\n",
      "step 37 // scores = [0.9907037019729614, 1.0000001192092896, 0.9840905666351318, 1.0, 0.9734113812446594, 0.9999957084655762, 0.9954445362091064, 1.0, 1.0, 1.0, 0.990042507648468, 0.9888860583305359, 0.9893577694892883, 0.9980506896972656, 1.0000001192092896, 1.0]\n",
      "step 38 // scores = [0.9907037019729614, 1.0000001192092896, 0.9840836524963379, 1.0, 0.9734113812446594, 1.0000001192092896, 0.995468020439148, 0.9999960660934448, 1.0, 1.0, 0.9900641441345215, 0.9889380931854248, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 39 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 0.9994629621505737, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9889380931854248, 0.9893554449081421, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 40 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 0.9994671940803528, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 1.0, 0.990042507648468, 0.9889380931854248, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 41 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 0.999995231628418, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 0.9999971389770508, 0.990042507648468, 0.9889696836471558, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 42 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 0.9999988079071045, 0.9999961256980896, 0.9900641441345215, 0.9889380931854248, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 43 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9734113812446594, 1.0000001192092896, 0.9954624176025391, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9889380931854248, 0.9893577694892883, 0.9980680346488953, 1.0000001192092896, 1.0]\n",
      "step 44 // scores = [0.9906760454177856, 1.0000001192092896, 0.984053909778595, 0.999995231628418, 0.9734113812446594, 1.0000001192092896, 0.9954610466957092, 1.0, 1.0, 0.9999961256980896, 0.990017831325531, 0.988947868347168, 0.9893577694892883, 0.9980193972587585, 1.0000001192092896, 1.0]\n",
      "step 45 // scores = [0.9907037019729614, 1.0000001192092896, 0.9840389490127563, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9889380931854248, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 46 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9889696836471558, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 47 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954445362091064, 1.0, 1.0, 0.9999980926513672, 0.9900641441345215, 0.9889380931854248, 0.9893577694892883, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 48 // scores = [0.9906760454177856, 0.9999973177909851, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9954208135604858, 0.9999960660934448, 1.0, 1.0, 0.9900641441345215, 0.9889380931854248, 0.9893554449081421, 0.9980506896972656, 1.0000001192092896, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating from val:  25%|█████████████████████████████▊                                                                                         | 1/4 [06:41<20:04, 401.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49 // scores = [0.9907037019729614, 1.0000001192092896, 0.9840836524963379, 1.0, 0.9734113812446594, 0.9999974966049194, 0.9954440593719482, 1.0, 1.0, 0.9999980926513672, 0.9901243448257446, 0.9889380931854248, 0.9893858432769775, 0.9980581998825073, 1.0000001192092896, 1.0]\n",
      "step 0 // scores = [0.9685827493667603, 0.9302715063095093, 0.9665138125419617, 0.9878214597702026, 0.9471046328544617, 0.9748519659042358, 0.9567849636077881, 0.9813622236251831, 0.9869804382324219, 0.9263976216316223, 0.9716642498970032, 0.9937050342559814, 0.9699698090553284, 0.9730018377304077, 0.9999697804450989, 0.9787521362304688]\n",
      "step 1 // scores = [0.9889158606529236, 0.9644853472709656, 0.9852544069290161, 0.9958232641220093, 0.9653846025466919, 0.978120744228363, 0.9674550294876099, 0.9902399778366089, 0.9942042231559753, 0.9364060163497925, 0.9804080128669739, 0.9999949932098389, 0.9833235740661621, 1.000000238418579, 1.0, 0.9869739413261414]\n",
      "step 2 // scores = [0.9924609065055847, 0.9684945344924927, 0.9926201701164246, 1.0000001192092896, 0.9741077423095703, 0.9924583435058594, 0.9790446758270264, 1.000000238418579, 0.9956175088882446, 0.9495255351066589, 0.9941281080245972, 1.000000238418579, 0.9848340153694153, 1.000000238418579, 0.9999955892562866, 0.9902681708335876]\n",
      "step 3 // scores = [0.9940580725669861, 0.9714066386222839, 0.9967775344848633, 1.0000001192092896, 0.9741077423095703, 0.9999949336051941, 0.9816380143165588, 1.000000238418579, 0.9956042766571045, 0.9496654272079468, 1.0000001192092896, 0.9999959468841553, 0.9850085377693176, 1.000000238418579, 0.9999955892562866, 0.9918357133865356]\n",
      "step 4 // scores = [0.9965711832046509, 0.9766398668289185, 0.9968039393424988, 1.0000001192092896, 0.9741077423095703, 0.9999949336051941, 0.9832128882408142, 1.000000238418579, 0.9956042766571045, 0.9562785625457764, 0.9999969005584717, 1.000000238418579, 0.9890505075454712, 1.000000238418579, 0.9999697804450989, 0.9979336261749268]\n",
      "step 5 // scores = [0.9996392726898193, 0.9787322282791138, 0.9967933893203735, 0.9999983906745911, 0.9742017984390259, 1.0000001192092896, 0.9872466921806335, 1.000000238418579, 0.9956324100494385, 0.9563016891479492, 0.9999971985816956, 0.9999959468841553, 0.9940124154090881, 1.000000238418579, 1.0, 0.9979336261749268]\n",
      "step 6 // scores = [0.9996306896209717, 0.9789265990257263, 0.9967933893203735, 0.9999983906745911, 0.9747126698493958, 0.9999949336051941, 0.9872761368751526, 1.000000238418579, 0.9956324100494385, 0.9562930464744568, 0.9999969005584717, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 1.0, 0.9979336261749268]\n",
      "step 7 // scores = [0.9997991323471069, 0.9840171337127686, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 0.9999949336051941, 0.9882772564888, 1.000000238418579, 0.9956246018409729, 0.9563469290733337, 0.9999971985816956, 0.9999980926513672, 0.9978044033050537, 1.000000238418579, 0.9999955892562866, 1.0]\n",
      "step 8 // scores = [0.9999974370002747, 0.9840171337127686, 1.0000001192092896, 0.9999983906745911, 0.9746485948562622, 0.9999949336051941, 0.9874403476715088, 1.000000238418579, 0.9956324100494385, 0.9562785625457764, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 0.9999950528144836, 0.9999982118606567]\n",
      "step 9 // scores = [0.9999975562095642, 0.9840347766876221, 1.0000001192092896, 0.9999983906745911, 0.9746609330177307, 1.0000001192092896, 0.9873957633972168, 0.9999974370002747, 0.9956042766571045, 0.9562785625457764, 0.9999969005584717, 0.9999949932098389, 0.9978145360946655, 0.9999986290931702, 1.0, 0.9999983906745911]\n",
      "step 10 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 1.0000001192092896, 0.9873957633972168, 0.9999973773956299, 0.9956246018409729, 0.9563016891479492, 0.9999969005584717, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 1.0, 1.0]\n",
      "step 11 // scores = [0.9999977946281433, 0.9845268726348877, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 1.0000001192092896, 0.9874403476715088, 1.000000238418579, 0.9956324100494385, 0.9640129804611206, 1.0000001192092896, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 1.0, 0.9999983906745911]\n",
      "step 12 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 1.0000001192092896, 0.9874403476715088, 1.000000238418579, 0.9956175088882446, 0.96405029296875, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 1.0, 1.0]\n",
      "step 13 // scores = [0.9999975562095642, 0.9845657348632812, 1.0000001192092896, 0.9999983906745911, 0.9746485948562622, 1.0000001192092896, 0.9874403476715088, 1.000000238418579, 0.9956175088882446, 0.959333598613739, 0.9999969005584717, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 14 // scores = [0.9999975562095642, 0.9845657348632812, 1.0000001192092896, 0.9999983906745911, 0.9746485948562622, 0.9999949336051941, 0.9874403476715088, 1.000000238418579, 0.9956324100494385, 0.9593504667282104, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 0.9999969005584717, 1.0]\n",
      "step 15 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 0.9999949336051941, 0.9874403476715088, 0.9999980926513672, 0.9956175088882446, 0.9658849835395813, 0.9999969005584717, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999956488609314, 1.0]\n",
      "step 16 // scores = [0.9999963045120239, 0.9845517873764038, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 1.0000001192092896, 0.9874403476715088, 0.9999980926513672, 0.9956246018409729, 0.9658604860305786, 0.9999971985816956, 0.999995231628418, 0.9978145360946655, 1.000000238418579, 1.0, 1.0]\n",
      "step 17 // scores = [0.9999974370002747, 0.9845268726348877, 1.0000001192092896, 0.9999983906745911, 0.9746567010879517, 0.9999949336051941, 0.9879270195960999, 1.000000238418579, 0.9956042766571045, 0.9658842086791992, 0.9999969005584717, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 18 // scores = [0.9999974370002747, 0.9845365285873413, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 1.0000001192092896, 0.9882287979125977, 0.9999980926513672, 0.9956042766571045, 0.9658849835395813, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 1.0, 0.9999963045120239]\n",
      "step 19 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.974662184715271, 0.9999959468841553, 0.989888072013855, 0.9999980926513672, 0.9956324100494385, 0.965912938117981, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 1.0, 1.0]\n",
      "step 20 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.97472083568573, 0.9999951124191284, 0.992370069026947, 1.000000238418579, 0.9956042766571045, 0.9658842086791992, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 1.0, 1.0]\n",
      "step 21 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.97472083568573, 0.9999957084655762, 0.9931321144104004, 0.9999980926513672, 0.9956246018409729, 0.9659346342086792, 0.9999971985816956, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 22 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 1.0000001192092896, 0.9931321144104004, 1.000000238418579, 0.9956324100494385, 0.965912938117981, 1.0000001192092896, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999955892562866, 1.0]\n",
      "step 23 // scores = [0.9999946355819702, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 1.0000001192092896, 0.9931321144104004, 1.000000238418579, 0.9956042766571045, 0.9658849835395813, 0.9999969005584717, 0.9999959468841553, 0.9978145360946655, 1.000000238418579, 1.0, 1.0]\n",
      "step 24 // scores = [0.9999946355819702, 0.9845657348632812, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 0.9999949336051941, 0.9931328296661377, 0.9999963641166687, 0.995650053024292, 0.965903639793396, 1.0000001192092896, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999955892562866, 1.0]\n",
      "step 25 // scores = [0.9999975562095642, 0.9845365285873413, 0.9999978542327881, 1.0000001192092896, 0.9746485948562622, 0.9999949336051941, 0.9931321144104004, 0.9999980926513672, 0.9956042766571045, 0.9658842086791992, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 0.9999955892562866, 1.0]\n",
      "step 26 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 0.9999983906745911, 0.9746485948562622, 1.0000001192092896, 0.9931328296661377, 0.9999974370002747, 0.9956324100494385, 0.9658566117286682, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 0.9999955892562866, 1.0]\n",
      "step 27 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 0.9999971389770508, 0.9931321144104004, 1.000000238418579, 0.9956042766571045, 0.9658849835395813, 1.0000001192092896, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 1.0, 1.0]\n",
      "step 28 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 0.9999983906745911, 0.9746485948562622, 0.9999949336051941, 0.9931321144104004, 1.000000238418579, 0.9956324100494385, 0.9658842086791992, 1.0000001192092896, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999955892562866, 1.0]\n",
      "step 29 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746567010879517, 0.9999964833259583, 0.9931321144104004, 1.000000238418579, 0.9956042766571045, 0.9659346342086792, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 0.9999983310699463, 1.0, 1.0]\n",
      "step 30 // scores = [0.9999975562095642, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 1.0000001192092896, 0.9931308627128601, 1.000000238418579, 0.9956042766571045, 0.9658603072166443, 0.9999969005584717, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999955892562866, 1.0]\n",
      "step 31 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 0.9999983906745911, 0.97472083568573, 1.0000001192092896, 0.9931321144104004, 0.9999980926513672, 0.9956175088882446, 0.965912938117981, 0.9999969005584717, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 1.0, 0.9999963045120239]\n",
      "step 32 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 0.9999983906745911, 0.9746485948562622, 1.0000001192092896, 0.9931373596191406, 0.9999980926513672, 0.9956324100494385, 0.9659346342086792, 1.0000001192092896, 0.9999959468841553, 0.9978145360946655, 1.000000238418579, 0.9999955892562866, 1.0]\n",
      "step 33 // scores = [0.9999975562095642, 0.9845551252365112, 1.0000001192092896, 1.0000001192092896, 0.9746404886245728, 0.9999964833259583, 0.9931321144104004, 0.9999980926513672, 0.9956042766571045, 0.9658842086791992, 0.9999974966049194, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 1.0, 1.0]\n",
      "step 34 // scores = [0.9999977946281433, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746567010879517, 1.0000001192092896, 0.9931321144104004, 1.000000238418579, 0.9956042766571045, 0.965912938117981, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 0.9999955892562866, 0.9999983906745911]\n",
      "step 35 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 0.9999967813491821, 0.9931321144104004, 1.000000238418579, 0.9956042766571045, 0.9658842086791992, 0.9999969005584717, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 36 // scores = [0.9999977946281433, 0.9845490455627441, 1.0000001192092896, 0.9999983906745911, 0.9746485948562622, 1.0000001192092896, 0.9931328296661377, 0.9999973773956299, 0.9956324100494385, 0.965903639793396, 0.9999969005584717, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 37 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 0.999998927116394, 0.97472083568573, 1.0000001192092896, 0.9931321144104004, 0.9999980926513672, 0.9956042766571045, 0.9561869502067566, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 38 // scores = [0.9999974370002747, 0.9845365285873413, 0.9999978542327881, 1.0000001192092896, 0.9747126698493958, 0.9999949336051941, 0.9931321144104004, 0.9999980926513672, 0.9956324100494385, 0.965912938117981, 0.9999969005584717, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 1.0, 0.9999983906745911]\n",
      "step 39 // scores = [1.000000238418579, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 1.0000001192092896, 0.9931321144104004, 1.000000238418579, 0.9956042766571045, 0.9658566117286682, 1.0000001192092896, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 40 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.97472083568573, 0.9999949336051941, 0.9931321144104004, 1.000000238418579, 0.9956042766571045, 0.9658842086791992, 0.9999969005584717, 0.9999950528144836, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 41 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 0.9999983906745911, 0.9746485948562622, 0.9999949336051941, 0.9931321144104004, 1.000000238418579, 0.9956324100494385, 0.9658849835395813, 0.9999969005584717, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 42 // scores = [0.9999974370002747, 0.9845657348632812, 1.0000001192092896, 0.9999983906745911, 0.9746485948562622, 1.0000001192092896, 0.9931321144104004, 1.000000238418579, 0.9956042766571045, 0.9658842086791992, 0.9999969005584717, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 1.0, 1.0]\n",
      "step 43 // scores = [0.9999977946281433, 0.9845657348632812, 1.0000001192092896, 0.9999983906745911, 0.9746485948562622, 1.0000001192092896, 0.9931321144104004, 1.000000238418579, 0.9956324100494385, 0.965903639793396, 1.0000001192092896, 0.9999959468841553, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 44 // scores = [0.9999977946281433, 0.9845490455627441, 1.0000001192092896, 1.0000001192092896, 0.9746567010879517, 1.0000001192092896, 0.9931321144104004, 1.000000238418579, 0.9956042766571045, 0.9658842086791992, 0.9999969005584717, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 45 // scores = [0.9999974370002747, 0.9845365285873413, 1.0000001192092896, 1.0000001192092896, 0.9746485948562622, 1.0000001192092896, 0.9931321144104004, 0.9999980926513672, 0.9956324100494385, 0.9659346342086792, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 1.0, 0.9999983906745911]\n",
      "step 46 // scores = [0.9999975562095642, 0.9845365285873413, 1.0000001192092896, 1.0000001192092896, 0.9747126698493958, 1.0000001192092896, 0.9931321144104004, 1.000000238418579, 0.9956042766571045, 0.965912938117981, 1.0000001192092896, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999956488609314, 1.0]\n",
      "step 47 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 0.9999983906745911, 0.9746485948562622, 0.9999955892562866, 0.9931321144104004, 1.000000238418579, 0.9956184029579163, 0.9658842086791992, 1.0000001192092896, 1.000000238418579, 0.9978145360946655, 1.000000238418579, 0.9999697804450989, 1.0]\n",
      "step 48 // scores = [0.9999974370002747, 0.9845490455627441, 1.0000001192092896, 0.999998927116394, 0.9746485948562622, 1.0000001192092896, 0.9931373596191406, 1.000000238418579, 0.9956042766571045, 0.9658842086791992, 1.0000001192092896, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 1.0, 0.9999983906745911]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating from val:  50%|███████████████████████████████████████████████████████████▌                                                           | 2/4 [13:32<13:34, 407.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49 // scores = [0.9999974370002747, 0.9845365285873413, 1.0000001192092896, 1.0000001192092896, 0.974662184715271, 1.0000001192092896, 0.9931321144104004, 1.000000238418579, 0.9956175088882446, 0.9658849835395813, 0.9999969005584717, 0.9999949932098389, 0.9978145360946655, 1.000000238418579, 0.9999955892562866, 1.0]\n",
      "step 0 // scores = [0.9741170406341553, 0.9816648960113525, 0.9615615606307983, 0.9965773224830627, 0.9904344081878662, 0.9942212104797363, 0.9987592101097107, 0.9756024479866028, 0.9725961089134216, 0.9911673069000244, 0.9383181929588318, 0.9888406991958618, 0.9934689998626709, 0.9787845015525818, 0.9695495367050171, 0.9667110443115234]\n",
      "step 1 // scores = [0.9979705214500427, 0.9955863356590271, 0.9820874929428101, 0.9967617988586426, 0.9958438873291016, 0.9953989386558533, 1.0, 1.0, 0.9767348766326904, 0.9958035945892334, 0.9607203602790833, 0.9918820261955261, 0.9999999403953552, 0.9990626573562622, 0.9999986886978149, 0.992803692817688]\n",
      "step 2 // scores = [1.000000238418579, 0.9963188171386719, 0.9951972961425781, 1.0, 0.9971380829811096, 0.9957250356674194, 1.0, 0.9999972581863403, 0.9746963977813721, 0.9960018396377563, 0.9704340696334839, 0.9999954700469971, 0.9999999403953552, 1.0, 1.0, 0.9958004951477051]\n",
      "step 3 // scores = [1.000000238418579, 0.9966061115264893, 0.9953160881996155, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 0.989965558052063, 0.9966052174568176, 0.9718545079231262, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9956873655319214]\n",
      "step 4 // scores = [1.000000238418579, 0.9966514706611633, 0.9953159689903259, 1.0, 1.0, 0.9957162141799927, 1.0, 1.0, 0.9923363924026489, 0.9999974370002747, 0.985517144203186, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9956535696983337]\n",
      "step 5 // scores = [1.000000238418579, 0.9966476559638977, 0.9953358173370361, 1.0, 1.0, 0.9957162141799927, 1.0, 1.0, 0.9923369884490967, 1.0, 0.9896005988121033, 1.0, 0.9992640018463135, 1.0, 1.0, 0.9956873655319214]\n",
      "step 6 // scores = [1.000000238418579, 0.9966476559638977, 0.9953056573867798, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 0.9931401610374451, 0.9999974966049194, 0.9936447143554688, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 7 // scores = [1.000000238418579, 0.9966534376144409, 0.9953384399414062, 1.0, 1.0, 0.9957162141799927, 1.0, 1.0, 0.9932066202163696, 0.999998152256012, 0.9936447143554688, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9956535696983337]\n",
      "step 8 // scores = [1.000000238418579, 0.9966514706611633, 0.9953159689903259, 1.0, 0.9999963045120239, 0.9957250356674194, 1.0, 1.0, 0.9949057102203369, 0.9999974966049194, 0.9966596364974976, 1.0, 0.9992645382881165, 1.0, 1.0, 0.9957013130187988]\n",
      "step 9 // scores = [1.000000238418579, 0.9966514706611633, 0.9953160881996155, 1.0, 1.0, 0.9957165122032166, 1.0, 1.0, 0.9949057102203369, 0.9999974966049194, 0.9965826869010925, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 10 // scores = [1.000000238418579, 0.9966514706611633, 0.9953275322914124, 1.0, 1.0, 0.995683491230011, 1.0, 1.0, 0.9949599504470825, 0.9999974966049194, 0.9976082444190979, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 11 // scores = [1.000000238418579, 0.9966415166854858, 0.9953056573867798, 1.0, 1.0, 0.9957162141799927, 1.0, 1.0, 0.9956735968589783, 0.9999974966049194, 0.9980632066726685, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 12 // scores = [1.000000238418579, 0.9966415166854858, 0.9953056573867798, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 0.997173011302948, 0.9999974966049194, 0.9980632066726685, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 13 // scores = [1.000000238418579, 0.9966415166854858, 0.9953159689903259, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9980131387710571, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 14 // scores = [0.9999966025352478, 0.9966415166854858, 0.9953160881996155, 1.0, 1.0, 0.9957165122032166, 1.0, 1.0, 0.999995231628418, 1.0, 0.9980131387710571, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 15 // scores = [1.000000238418579, 0.9966514706611633, 0.9953384399414062, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9980632066726685, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 16 // scores = [0.9999969005584717, 0.9966514706611633, 0.9953160881996155, 1.0, 1.0, 0.9957162141799927, 1.0, 1.0, 1.0000001192092896, 0.9999974370002747, 0.9980553388595581, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9956873655319214]\n",
      "step 17 // scores = [1.000000238418579, 0.9966415166854858, 0.9953439831733704, 0.9999978542327881, 1.0, 0.9957165122032166, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 0.9981724619865417, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 18 // scores = [1.000000238418579, 0.9966476559638977, 0.9953358173370361, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 0.9999958872795105, 0.9999964833259583, 1.000000238418579, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 19 // scores = [1.000000238418579, 0.9966415166854858, 0.9953160881996155, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 0.9999964833259583, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 20 // scores = [1.000000238418579, 0.9966415166854858, 0.9953056573867798, 1.0, 0.9999979734420776, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.999998152256012, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 21 // scores = [0.9999969005584717, 0.9966476559638977, 0.9953384399414062, 0.9999974370002747, 1.0, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 22 // scores = [1.000000238418579, 0.9966415166854858, 0.9953160881996155, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.999998152256012, 1.000000238418579, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 23 // scores = [1.000000238418579, 0.9966514706611633, 0.9953056573867798, 0.9999972581863403, 1.0, 0.9957162141799927, 0.9999984502792358, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9956572651863098]\n",
      "step 24 // scores = [1.000000238418579, 0.9966415166854858, 0.9953384399414062, 0.9999973773956299, 1.0, 0.9957235455513, 0.9999345541000366, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9956616759300232]\n",
      "step 25 // scores = [1.000000238418579, 0.9966415166854858, 0.9953384399414062, 0.9999972581863403, 0.9999987483024597, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 1.0, 1.000000238418579, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 26 // scores = [1.000000238418579, 0.9966514706611633, 0.9953056573867798, 1.0, 0.9999987483024597, 0.9957235455513, 1.0, 1.0, 1.0000001192092896, 1.0, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 27 // scores = [1.000000238418579, 0.9966534376144409, 0.9953384399414062, 0.9999974370002747, 0.9999964237213135, 0.9957235455513, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 28 // scores = [1.000000238418579, 0.9966472387313843, 0.9953159689903259, 1.0, 1.0, 0.9957162141799927, 0.9999778270721436, 1.0, 1.0000001192092896, 0.9999964833259583, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 29 // scores = [1.000000238418579, 0.9966514706611633, 0.9953056573867798, 1.0, 1.0, 0.9957162141799927, 1.0, 1.0, 1.0000001192092896, 0.9999964833259583, 0.9999982714653015, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9956873655319214]\n",
      "step 30 // scores = [1.000000238418579, 0.9966514706611633, 0.9953056573867798, 1.0, 0.9999987483024597, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.999998152256012, 1.000000238418579, 0.9999961256980896, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 31 // scores = [1.000000238418579, 0.9966415166854858, 0.995314359664917, 1.0, 0.9999960660934448, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 0.9999977350234985, 0.9999971389770508, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 32 // scores = [0.9999973773956299, 0.9966537952423096, 0.9953160881996155, 1.0, 1.0, 0.9957162141799927, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 33 // scores = [1.000000238418579, 0.9966415166854858, 0.9953358173370361, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.9999964833259583, 1.000000238418579, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 34 // scores = [1.000000238418579, 0.9966415166854858, 0.9953056573867798, 1.0, 0.9999979734420776, 0.9957250356674194, 1.0, 1.0, 0.9999955892562866, 0.999998152256012, 1.000000238418579, 0.9999961256980896, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 35 // scores = [1.000000238418579, 0.9966514706611633, 0.9953056573867798, 1.0, 1.0, 0.9957162141799927, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 36 // scores = [1.000000238418579, 0.9966514706611633, 0.9953159689903259, 0.9999973773956299, 1.0, 0.9957162141799927, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 37 // scores = [1.000000238418579, 0.9966415166854858, 0.995324969291687, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 38 // scores = [0.9999969005584717, 0.9966514706611633, 0.9953056573867798, 1.0, 1.0, 0.9957162141799927, 1.0, 0.999997615814209, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 39 // scores = [1.000000238418579, 0.9966514706611633, 0.9953358173370361, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.9999964833259583, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 40 // scores = [1.000000238418579, 0.9966514706611633, 0.9953384399414062, 0.9999974966049194, 0.9999987483024597, 0.9957235455513, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 41 // scores = [1.000000238418579, 0.9966476559638977, 0.9953358173370361, 0.9999974370002747, 1.0, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9956873655319214]\n",
      "step 42 // scores = [1.000000238418579, 0.9966415166854858, 0.9953160881996155, 0.9999974370002747, 1.0, 0.9957016110420227, 1.0, 0.9999973773956299, 1.0000001192092896, 0.9999964833259583, 0.9999982714653015, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9956873655319214]\n",
      "step 43 // scores = [1.000000238418579, 0.9966415166854858, 0.9953160881996155, 1.0, 1.0, 0.9957162141799927, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9956873655319214]\n",
      "step 44 // scores = [1.000000238418579, 0.9966415166854858, 0.9953384399414062, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 45 // scores = [1.000000238418579, 0.9966514706611633, 0.9953160881996155, 1.0, 1.0, 0.9957162141799927, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 1.0, 1.0, 0.9957013130187988]\n",
      "step 46 // scores = [1.000000238418579, 0.9966415166854858, 0.9953160881996155, 1.0, 1.0, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 0.9999982714653015, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 47 // scores = [1.000000238418579, 0.9966534376144409, 0.9953160881996155, 1.0, 0.9999979734420776, 0.9957250356674194, 1.0, 1.0, 1.0000001192092896, 0.9999964833259583, 1.000000238418579, 0.9999961256980896, 0.9999999403953552, 1.0, 1.0, 0.9956873655319214]\n",
      "step 48 // scores = [1.000000238418579, 0.9966514706611633, 0.9953160881996155, 1.0, 1.0, 0.9957162141799927, 1.0, 1.0, 1.0000001192092896, 0.9999974966049194, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating from val:  75%|█████████████████████████████████████████████████████████████████████████████████████████▎                             | 3/4 [20:10<06:42, 402.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49 // scores = [1.000000238418579, 0.9966415166854858, 0.9953358173370361, 0.9999974370002747, 1.0, 0.9957250356674194, 1.0, 0.999997615814209, 1.0000001192092896, 0.9999974370002747, 1.000000238418579, 1.0, 0.9999999403953552, 0.9999984502792358, 1.0, 0.9957013130187988]\n",
      "step 0 // scores = [0.9647430181503296, 0.9164119958877563, 0.9921476244926453, 1.0000001192092896, 0.9836402535438538, 0.9770697951316833, 0.9679416418075562, 0.9844198226928711, 0.9915122985839844, 0.9699249863624573, 0.9694809913635254, 0.9806356430053711, 0.9834069013595581, 0.9955090284347534, 0.9865548610687256, 1.0]\n",
      "step 1 // scores = [0.9700803756713867, 0.9683348536491394, 0.999359130859375, 1.0000001192092896, 0.9969849586486816, 0.9885216951370239, 0.9831531047821045, 0.9862316846847534, 0.995763897895813, 0.9805130958557129, 0.9756686091423035, 0.991820752620697, 0.989282488822937, 1.0, 0.9836205840110779, 1.0]\n",
      "step 2 // scores = [0.9786548614501953, 0.9969747066497803, 1.0, 1.0000001192092896, 0.9999974370002747, 0.9960532784461975, 0.9821771383285522, 0.9904651641845703, 1.0, 0.9960986375808716, 0.9834911227226257, 0.9966014623641968, 0.9955431818962097, 1.0, 0.9848554134368896, 1.0]\n",
      "step 3 // scores = [0.990529477596283, 0.9999905824661255, 0.9999985694885254, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9909764528274536, 1.0, 0.9979482293128967, 0.9918164014816284, 0.9966014623641968, 0.9999974966049194, 1.0, 0.9864860773086548, 1.0]\n",
      "step 4 // scores = [0.9921290874481201, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843688011169434, 0.9913061857223511, 1.0, 0.9979482293128967, 0.9940415024757385, 0.9966014623641968, 0.9999977946281433, 1.0, 0.990673840045929, 1.0]\n",
      "step 5 // scores = [0.9926525354385376, 1.0, 0.9999983310699463, 1.0000001192092896, 0.9999974370002747, 0.9960569143295288, 0.9843623042106628, 0.9915372133255005, 1.0, 0.9979482293128967, 0.9957842230796814, 0.9966016411781311, 1.0000001192092896, 1.0, 0.9907065629959106, 0.9999992847442627]\n",
      "step 6 // scores = [0.9926766157150269, 0.9999934434890747, 0.9999983310699463, 1.0000001192092896, 1.0, 0.9960724115371704, 0.984343945980072, 0.9915372133255005, 1.0, 0.9979482293128967, 0.9995743036270142, 0.99693763256073, 1.0000001192092896, 1.0, 0.9924252033233643, 1.0]\n",
      "step 7 // scores = [0.9926766157150269, 1.0, 1.0, 0.9999974966049194, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 0.9999960660934448, 0.997946560382843, 1.0, 0.9966155290603638, 1.0000001192092896, 1.0, 0.9924252033233643, 1.0]\n",
      "step 8 // scores = [0.992658257484436, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843614101409912, 0.9915372133255005, 1.0, 0.9979482293128967, 1.0, 0.9969339966773987, 1.0000001192092896, 1.0, 0.9924589395523071, 0.9999992847442627]\n",
      "step 9 // scores = [0.9926542639732361, 1.0, 0.9999983310699463, 0.9999974966049194, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.9966014623641968, 1.0000001192092896, 1.0, 0.9924252033233643, 1.0]\n",
      "step 10 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843688011169434, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924252033233643, 1.0]\n",
      "step 11 // scores = [0.9926542639732361, 1.0, 0.9999976754188538, 0.9999972581863403, 0.9999943971633911, 0.9960724115371704, 0.9843688011169434, 0.9915186166763306, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 12 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 1.0, 0.9979444146156311, 1.0, 0.9972962141036987, 1.0000001192092896, 1.0, 0.992671012878418, 1.0]\n",
      "step 13 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.997312605381012, 1.0000001192092896, 0.9999959468841553, 0.9924919009208679, 1.0]\n",
      "step 14 // scores = [0.9926542639732361, 1.0, 0.9999983310699463, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915372133255005, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 0.9999959468841553, 0.9924919009208679, 1.0]\n",
      "step 15 // scores = [0.9926542639732361, 1.0, 0.9999983310699463, 1.0000001192092896, 1.0, 0.9960692524909973, 0.9843623042106628, 0.9915273189544678, 0.9999966621398926, 0.9979482293128967, 1.0, 0.9973049759864807, 1.0000001192092896, 1.0, 0.9927577972412109, 0.9999992847442627]\n",
      "step 16 // scores = [0.9926542639732361, 1.0, 0.9999985694885254, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 0.9999966621398926, 0.9979472160339355, 1.0, 0.9972954988479614, 1.0000001192092896, 0.9999955892562866, 0.9927577972412109, 1.0]\n",
      "step 17 // scores = [0.9926542639732361, 1.0, 1.0, 0.9999974966049194, 1.0, 0.9960724115371704, 0.9843688011169434, 0.9915372133255005, 1.0, 0.9979472160339355, 1.0, 0.9972954988479614, 1.0000001192092896, 0.9999959468841553, 0.9924919009208679, 1.0]\n",
      "step 18 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843847155570984, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 19 // scores = [0.9926542639732361, 0.9999934434890747, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 0.9999973177909851, 0.9979482293128967, 1.0, 0.9973049759864807, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 20 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 0.9999966621398926, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 21 // scores = [0.9926542639732361, 1.0, 0.9999983310699463, 1.0000001192092896, 1.0, 0.9960728883743286, 0.9843688011169434, 0.9915372133255005, 1.0, 0.9979482293128967, 1.0, 0.997312605381012, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 22 // scores = [0.992658257484436, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960692524909973, 0.9843623042106628, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.997312605381012, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 23 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915372133255005, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9926555156707764, 1.0]\n",
      "step 24 // scores = [0.9926766157150269, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915372133255005, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 25 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843614101409912, 0.991491436958313, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.992671012878418, 1.0]\n",
      "step 26 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924819469451904, 1.0]\n",
      "step 27 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843614101409912, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.997312605381012, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 28 // scores = [0.992658257484436, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915372133255005, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 29 // scores = [0.9926596879959106, 0.9999934434890747, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915372133255005, 1.0, 0.9979482293128967, 0.9999890923500061, 0.9973049759864807, 1.0000001192092896, 1.0, 0.992671012878418, 1.0]\n",
      "step 30 // scores = [0.9926542639732361, 0.9999934434890747, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 0.9999961853027344, 0.9979482293128967, 1.0, 0.997312605381012, 1.0000001192092896, 1.0, 0.992671012878418, 1.0]\n",
      "step 31 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 32 // scores = [0.9926542639732361, 1.0, 0.9999978542327881, 0.9999865889549255, 1.0, 0.9960636496543884, 0.9843688011169434, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9927537441253662, 0.9999992251396179]\n",
      "step 33 // scores = [0.9926596879959106, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960554242134094, 0.9843614101409912, 0.9915372133255005, 1.0, 0.9979482293128967, 1.0, 0.9973049759864807, 1.0000001192092896, 1.0, 0.9924866557121277, 1.0]\n",
      "step 34 // scores = [0.9926766157150269, 1.0, 1.0, 0.9999974966049194, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.9973049759864807, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 35 // scores = [0.9926542639732361, 1.0, 1.0, 0.9999972581863403, 1.0, 0.9960724115371704, 0.984343945980072, 0.9915372133255005, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 36 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960692524909973, 0.984343945980072, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 37 // scores = [0.9926542639732361, 0.9999932646751404, 1.0, 0.9999974966049194, 0.9999974370002747, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 1.0, 0.9979482293128967, 0.9999956488609314, 0.997312605381012, 1.0000001192092896, 0.9999960660934448, 0.992671012878418, 1.0]\n",
      "step 38 // scores = [0.9926568269729614, 1.0, 0.9999983310699463, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843614101409912, 0.9915372133255005, 1.0, 0.9979482293128967, 1.0, 0.9973049759864807, 1.0000001192092896, 0.9999955892562866, 0.9924919009208679, 1.0]\n",
      "step 39 // scores = [0.9926542639732361, 1.0, 1.0, 0.9999972581863403, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915372133255005, 0.9999960064888, 0.9979482293128967, 1.0, 0.9973106384277344, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 40 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9853881001472473, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 41 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960554242134094, 0.9843614101409912, 0.9915372133255005, 0.9999960064888, 0.9979519844055176, 1.0, 0.9973002672195435, 1.0000001192092896, 1.0, 0.992671012878418, 1.0]\n",
      "step 42 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915139675140381, 1.0, 0.9979482293128967, 1.0, 0.9973049759864807, 1.0000001192092896, 1.0, 0.992671012878418, 1.0]\n",
      "step 43 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 0.9999943971633911, 0.9960636496543884, 0.9843623042106628, 0.9915273189544678, 1.0, 0.9979482293128967, 0.9999962449073792, 0.9973196387290955, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 44 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 0.9999966621398926, 0.9979482293128967, 1.0, 0.9973130226135254, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 45 // scores = [0.9926568269729614, 1.0, 0.9999983310699463, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.992671012878418, 1.0]\n",
      "step 46 // scores = [0.9926546812057495, 0.9999905824661255, 0.9999974966049194, 1.0000001192092896, 1.0, 0.9960692524909973, 0.9843623042106628, 0.991491436958313, 0.9999966621398926, 0.9979472160339355, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n",
      "step 47 // scores = [0.9926542639732361, 1.0, 1.0, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915372133255005, 1.0, 0.9979482293128967, 0.9999956488609314, 0.9973080158233643, 1.0000001192092896, 1.0, 0.9927577972412109, 1.0]\n",
      "step 48 // scores = [0.9926596879959106, 1.0, 1.0, 0.9999974966049194, 1.0, 0.9960724115371704, 0.9843614101409912, 0.9915372133255005, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 0.9999959468841553, 0.9924919009208679, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating from val: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [26:40<00:00, 397.71s/it]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000d03ff0ac8000016cc'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000e8397ddbc000016cb'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000d83c12d9e000016ca'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000e019fe9ff000016c9'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49 // scores = [0.9926542639732361, 1.0, 0.9999985694885254, 1.0000001192092896, 1.0, 0.9960724115371704, 0.9843623042106628, 0.9915273189544678, 1.0, 0.9979482293128967, 1.0, 0.9972954988479614, 1.0000001192092896, 1.0, 0.9924919009208679, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] *The use of the driveway will require the use of separate parking spaces as required for a Use Permit. [submittal] Floor plan (\n",
      "[true] *The use of the driveway as the required parking spaces will require a separate submittal for a Use Permit. [ ] Floor plan (\n",
      "\n",
      "\n",
      "\n",
      "[pred] Our STREETWISE Seville Map enables you to explore each hidden corner of this enticing destination with a clearly defined map of\n",
      "[true] Our STREETWISE Seville Map enables you to explore each hidden corner of this enticing destination with a clearly defined map of\n",
      "\n",
      "\n",
      "\n",
      "[pred] aaa coupon com with 32 codes save an average of $ 26 aaa coupon deals about aaa com a\n",
      "[true] aaa coupon codes about aaa save an average of $ 32 with 26 coupon codes deals for aaa com a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7891451716423035,\n",
       " 'eval_pred_num_tokens': 31.0,\n",
       " 'eval_true_num_tokens': 32.0,\n",
       " 'eval_token_set_precision': 0.9583383272404813,\n",
       " 'eval_token_set_recall': 0.9615689698882466,\n",
       " 'eval_token_set_f1': 0.9596197528508108,\n",
       " 'eval_n_ngrams_match_1': 23.421875,\n",
       " 'eval_n_ngrams_match_2': 20.34375,\n",
       " 'eval_n_ngrams_match_3': 18.125,\n",
       " 'eval_num_true_words': 24.59375,\n",
       " 'eval_num_pred_words': 24.5625,\n",
       " 'eval_bleu_score': 83.9989272754478,\n",
       " 'eval_meteor_score': 0.9457946913499904,\n",
       " 'eval_rouge_score': 0.9575818665228042,\n",
       " 'eval_exact_match': 0.609375,\n",
       " 'eval_emb_cos_sim': 0.9962092638015747,\n",
       " 'eval_runtime': 1609.8632,\n",
       " 'eval_samples_per_second': 0.04,\n",
       " 'eval_steps_per_second': 0.002}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 16\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 50\n",
    "corr_trainer.sequence_beam_width = 8\n",
    "corr_trainer.return_best_hypothesis = True\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"msmarco\"].select(range(64)),\n",
    "    metric_key_prefix=\"eval\",\n",
    ")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdd95839-da17-4aab-80ed-3b8ac3ea3cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000038080d6fd000016d1'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000004826bfedf000016d2'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000301a88cfb000016cf'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000403f53999000016ce'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000287b10ae0000016d0'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000005031c2190000016cd'\n",
      "generating from val:   0%|                                                                                                                               | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 // scores = [0.9583866596221924, 0.9565423130989075, 0.9811453819274902, 0.9539602994918823, 0.9502842426300049, 0.9979091882705688, 0.9778316020965576, 0.9708535671234131, 0.998740553855896, 0.9788764715194702, 0.9858259558677673, 0.9718614816665649, 0.97817462682724, 0.9870227575302124, 0.9928306341171265, 0.9814497232437134]\n",
      "step 1 // scores = [0.982197642326355, 0.9835904240608215, 0.9831918478012085, 0.9880897998809814, 0.9746666550636292, 1.0000001192092896, 0.985980749130249, 0.9996954798698425, 1.0, 0.9893333911895752, 0.9872693419456482, 0.9783405065536499, 0.9867148399353027, 0.9927380084991455, 1.0000001192092896, 0.9912831783294678]\n",
      "step 2 // scores = [0.9872729182243347, 1.0000001192092896, 0.9831918478012085, 0.9988312721252441, 0.972139835357666, 1.0000001192092896, 0.9904456734657288, 1.0, 1.0, 0.9937753677368164, 0.9878878593444824, 0.9827227592468262, 0.9874004125595093, 0.9942857623100281, 1.0000001192092896, 0.9964807033538818]\n",
      "step 3 // scores = [0.9904642701148987, 1.0000001192092896, 0.984053909778595, 0.9990173578262329, 0.9759511947631836, 1.0000001192092896, 0.9919508099555969, 1.0, 1.0, 1.0, 0.990042507648468, 0.9860715866088867, 0.9882776737213135, 0.9953674077987671, 1.0000001192092896, 0.9979419708251953]\n",
      "step 4 // scores = [0.9902459383010864, 0.9999973177909851, 0.984053909778595, 1.0, 0.9730832576751709, 1.0000001192092896, 0.9922821521759033, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9860065579414368, 0.9893577694892883, 0.9954074025154114, 1.0000001192092896, 0.9999902248382568]\n",
      "step 5 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9730832576751709, 1.0000001192092896, 0.9925201535224915, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9888860583305359, 0.9893577694892883, 0.9965028762817383, 1.0000001192092896, 1.0]\n",
      "step 6 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.994964599609375, 1.0, 1.0, 0.9999971389770508, 0.9900641441345215, 0.9889380931854248, 0.9901576638221741, 0.9980359673500061, 1.0000001192092896, 1.0]\n",
      "step 7 // scores = [0.9907037019729614, 1.0000001192092896, 0.984053909778595, 1.0, 0.9733999967575073, 1.0000001192092896, 0.9949790835380554, 1.0, 1.0, 1.0, 0.9900641441345215, 0.9889380931854248, 0.9902939796447754, 0.9980581998825073, 1.0000001192092896, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000068325eac5000016d5'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000060aa80c26000016d4'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000781691c05000016d7'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000080acd25eb000016d8'\n",
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m corr_trainer\u001b[38;5;241m.\u001b[39msequence_beam_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m     11\u001b[0m corr_trainer\u001b[38;5;241m.\u001b[39mreturn_best_hypothesis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcorr_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorr_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmsmarco\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m metrics\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/transformers/trainer.py:3029\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3026\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3028\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3029\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3032\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3033\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3039\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/research/retrieval/inversion/trainers/corrector.py:154\u001b[0m, in \u001b[0;36mCorrectorTrainer.evaluation_loop\u001b[0;34m(self, dataloader, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mRun evaluation and returns metrics.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03mOverride to compute ppl from eval loss.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    153\u001b[0m metric_key_prefix \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_key_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 154\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_key_prefix \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_msmarco\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_nq\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    156\u001b[0m     n_rounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "File \u001b[0;32m~/research/retrieval/inversion/trainers/base.py:433\u001b[0m, in \u001b[0;36mBaseTrainer.evaluation_loop\u001b[0;34m(self, dataloader, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m metric_key_prefix \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_key_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# TODO compute some data metrics here too.\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m generation_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_generation_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m generation_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m generation_metrics\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    436\u001b[0m }\n\u001b[1;32m    437\u001b[0m output\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mupdate(generation_metrics)\n",
      "File \u001b[0;32m~/research/retrieval/inversion/trainers/base.py:314\u001b[0m, in \u001b[0;36mBaseTrainer.eval_generation_metrics\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_generation_metrics\u001b[39m(\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m, dataloader: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader\n\u001b[1;32m    311\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# Get decoded text. Note that this is different than `preds`, which\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# is used to compute the loss.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     preds_sample_list, preds_sample_labels_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_decoded_sequences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# Log BLEU, log table of text.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     decoded_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m    320\u001b[0m         preds_sample_list, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     )\n",
      "File \u001b[0;32m~/research/retrieval/inversion/trainers/base.py:132\u001b[0m, in \u001b[0;36mBaseTrainer._get_decoded_sequences\u001b[0;34m(self, dataloader, n)\u001b[0m\n\u001b[1;32m    130\u001b[0m gen_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m max_length\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 132\u001b[0m     generated_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_cuda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generated_text\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m max_length:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# Pad generated text to max length\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     pad_tokens \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    138\u001b[0m         torch\u001b[38;5;241m.\u001b[39mones(\n\u001b[1;32m    139\u001b[0m             (generated_text\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], max_length \u001b[38;5;241m-\u001b[39m generated_text\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencoder_decoder\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id\n\u001b[1;32m    144\u001b[0m     )\n",
      "File \u001b[0;32m~/research/retrieval/inversion/trainers/corrector.py:360\u001b[0m, in \u001b[0;36mCorrectorTrainer.generate\u001b[0;34m(self, inputs, generation_kwargs, num_recursive_steps, sequence_beam_width)\u001b[0m\n\u001b[1;32m    357\u001b[0m total_best_scores_seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Track best scores for early stopping\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m num_recursive_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 360\u001b[0m     gen_text_ids, hypothesis_embedding, best_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_beam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_recursive_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_recursive_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_recursive_steps_so_far\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_recursive_steps_so_far\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequence_beam_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence_beam_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m     inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhypothesis_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m gen_text_ids\n\u001b[1;32m    368\u001b[0m     inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhypothesis_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    369\u001b[0m         gen_text_ids \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencoder_decoder\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id\n\u001b[1;32m    370\u001b[0m     )\u001b[38;5;241m.\u001b[39mint()\n",
      "File \u001b[0;32m~/research/retrieval/inversion/trainers/corrector.py:451\u001b[0m, in \u001b[0;36mCorrectorTrainer._generate_with_beam\u001b[0;34m(self, inputs, generation_kwargs, num_recursive_steps, num_recursive_steps_so_far, sequence_beam_width)\u001b[0m\n\u001b[1;32m    449\u001b[0m     gen_text_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((bos_token_ids, gen_text_ids[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m     gen_text_ids \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msequences\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# get scores for sequences\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# https://discuss.huggingface.co/t/announcement-generation-get-probabilities-for-generated-output/30075\u001b[39;00m\n",
      "File \u001b[0;32m~/research/retrieval/inversion/models/corrector_encoder.py:159\u001b[0m, in \u001b[0;36mCorrectorEncoderModel.generate\u001b[0;34m(self, inputs, generation_kwargs, return_dict_in_generate)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_decoder\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;66;03m# required: input embeddings\u001b[39;00m\n\u001b[1;32m    147\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgeneration_kwargs,\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# required: input embeddings\u001b[39;49;00m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# optional: input IDs (for starting generation).\u001b[39;49;00m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# typically not set unless generating prefixes for\u001b[39;49;00m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# reranking.\u001b[39;49;00m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/transformers/generation/utils.py:1604\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1598\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1599\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1600\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1601\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1602\u001b[0m     )\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;66;03m# 13. run beam search\u001b[39;00m\n\u001b[0;32m-> 1604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/transformers/generation/utils.py:2978\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2975\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reorder_cache(model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m], beam_idx)\n\u001b[1;32m   2977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m output_scores:\n\u001b[0;32m-> 2978\u001b[0m     beam_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbeam_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[38;5;66;03m# increase cur_len\u001b[39;00m\n\u001b[1;32m   2981\u001b[0m cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/transformers/generation/utils.py:2978\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2975\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reorder_cache(model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m], beam_idx)\n\u001b[1;32m   2977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m output_scores:\n\u001b[0;32m-> 2978\u001b[0m     beam_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m((beam_indices[beam_idx[i]] \u001b[38;5;241m+\u001b[39m (beam_idx[i],) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(beam_indices))))\n\u001b[1;32m   2980\u001b[0m \u001b[38;5;66;03m# increase cur_len\u001b[39;00m\n\u001b[1;32m   2981\u001b[0m cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 16\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 50\n",
    "corr_trainer.sequence_beam_width = 8\n",
    "corr_trainer.return_best_hypothesis = True\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"msmarco\"].select(range(500)),\n",
    "    metric_key_prefix=\"eval\",\n",
    ")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e85331-4659-43eb-8ed8-7313737e4aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
