{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb92c7b-6b3d-4f26-af5a-f4e3fd555348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import sys\n",
    "sys.path = [\n",
    "    p for p in sys.path\n",
    "    if p not in ['/home/jxm3/research/prompting/imodelsX', '/home/jxm3/research/prompting/tree-prompt']\n",
    "]\n",
    "sys.path.append('/home/jxm3/research/retrieval/inversion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13a5ba8-8276-4598-bc19-716ec2fc3db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-28 15:46:32,352] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/jxm3/.conda/envs/torch/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "loading alias gtr_nq__msl32_beta__correct from /home/jxm3/research/retrieval/inversion/saves/47d9c149a8e827d0609abbeefdfd89ac...\n",
      "> checkpoint: /home/jxm3/research/retrieval/inversion/saves/47d9c149a8e827d0609abbeefdfd89ac/checkpoint-558000\n",
      "set dataset to nq\n",
      "Corrector encoder noise level 1e-05\n",
      "loading alias dpr_nq__msl32_beta from /home/jxm3/research/retrieval/inversion/saves/db66b9c01b644541fedbdcc59c53a285/ebb31d91810c4b62d2b55b5382e8c7ea...\n",
      "Set num workers to 4\n",
      "Overwriting max sequence length from 32 to 32\n",
      "Overwriting use_less_data from None to -1\n",
      "> checkpoint: /home/jxm3/research/retrieval/inversion/saves/db66b9c01b644541fedbdcc59c53a285/ebb31d91810c4b62d2b55b5382e8c7ea/checkpoint-999744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets with TOKENIZERS_PARALLELISM = False\n",
      "Renaming keys {'embedding_transform.2.weight', 'embedding_transform.2.bias'} for backward compatibility.\n",
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output shape ->  torch.Size([1, 33])\n",
      "\tDecoded output -> The mlbies wase wyst bograge; And the sliths and toms wy\n",
      "================ End trainer sanity check ================\n",
      "Froze 342572160 params from model type <class 'models.inversion.InversionModel'>\n",
      "Renaming keys {'embedding_transform.2.weight', 'embedding_transform.2.bias'} for backward compatibility.\n",
      "Renaming keys {'embedding_transform.2.weight', 'embedding_transform.2.bias'} for backward compatibility.\n",
      "================ Begin trainer sanity check ================\n",
      "\tInput to encode -> Twas brillig, and the slithy toves, Did gyre and gimble in the wabe, All mimsy were the borogoves, And the mome raths outgrabe.\n",
      "\tDecoded output shape ->  torch.Size([1, 33])\n",
      "\tDecoded output -> The slithe and the tobogbes were mly; It wis grabbse tiring\n",
      "================ End trainer sanity check ================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import aliases\n",
    "\n",
    "# inv_trainer = aliases.load_trainer_from_alias(\"openai_msmarco__msl128__100epoch\")\n",
    "corr_experiment, corr_trainer = aliases.load_experiment_and_trainer_from_alias(\"gtr_nq__msl32_beta__correct\")\n",
    "inv_trainer = corr_trainer.inversion_trainer\n",
    "# corr_trainer.precompute_hypotheses()\n",
    "corr_trainer.model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7629213-9875-4bbb-84ba-27b9e92ae9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_trainer.inversion_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60b0f91a-c949-48da-9e56-4403d55e8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = corr_trainer.inversion_trainer.get_eval_dataloader(corr_trainer.eval_dataset[\"nq\"].select(range(200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb6f9a91-7aff-4632-9bb4-09a216260944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.total_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bdb2f0f-5311-4f36-bc7d-c41e146a9631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000000012208600000729'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: {'input_ids': tensor([[   12,     8,  1848,  ...,    86,   685,     1],\n",
      "        [  928,    45,     8,  ...,  2051,    31,     1],\n",
      "        [    8,   337,  2166,  ...,    13,   454,     1],\n",
      "        ...,\n",
      "        [   28,  1476,    18,  ...,  2812,  2069,     1],\n",
      "        [ 2144,  2345,    41,  ...,  2345,     6,     1],\n",
      "        [ 7482,   291,    77,  ..., 14019,  6563,     1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'labels': tensor([[   12,     8,  1848,  ...,    86,   685,     1],\n",
      "        [  928,    45,     8,  ...,  2051,    31,     1],\n",
      "        [    8,   337,  2166,  ...,    13,   454,     1],\n",
      "        ...,\n",
      "        [   28,  1476,    18,  ...,  2812,  2069,     1],\n",
      "        [ 2144,  2345,    41,  ...,  2345,     6,     1],\n",
      "        [ 7482,   291,    77,  ..., 14019,  6563,     1]], device='cuda:0'), 'length': tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32], device='cuda:0'), 'embedder_input_ids': tensor([[   12,     8,  1848,  ...,    86,   685,     1],\n",
      "        [  928,    45,     8,  ...,  2051,    31,     1],\n",
      "        [    8,   337,  2166,  ...,    13,   454,     1],\n",
      "        ...,\n",
      "        [   28,  1476,    18,  ...,  2812,  2069,     1],\n",
      "        [ 2144,  2345,    41,  ...,  2345,     6,     1],\n",
      "        [ 7482,   291,    77,  ..., 14019,  6563,     1]], device='cuda:0'), 'embedder_attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating from val:   0%|                                                                                               | 0/1 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000008020003b0000072a'\n",
      "                                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] to the character of the skull, which are relatively smooth and untutuous in the case of infant sutures. Unlike the sutures,\n",
      "[true] to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "[pred] individual from the Southern Hemisphere to win the Winter Olympic relay gold medal, and was also part of the Australian Short Track team, which won gold\n",
      "[true] individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "[pred] the same rights as men, and 75% agreed that they should be protected from discrimination. Among the other 15%, gay workers are no longer exp\n",
      "[true] the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_nq_tiny_loss': 1.0422823429107666,\n",
       " 'eval_nq_tiny_accuracy': 0.74365234375,\n",
       " 'eval_nq_tiny_pred_num_tokens': 31.0,\n",
       " 'eval_nq_tiny_true_num_tokens': 32.0,\n",
       " 'eval_nq_tiny_token_set_precision': 0.655196786896353,\n",
       " 'eval_nq_tiny_token_set_recall': 0.6730567583994584,\n",
       " 'eval_nq_tiny_token_set_f1': 0.6624260465838063,\n",
       " 'eval_nq_tiny_token_set_f1_sem': 0.013345553268486863,\n",
       " 'eval_nq_tiny_n_ngrams_match_1': 16.0390625,\n",
       " 'eval_nq_tiny_n_ngrams_match_2': 8.9140625,\n",
       " 'eval_nq_tiny_n_ngrams_match_3': 5.8125,\n",
       " 'eval_nq_tiny_num_true_words': 24.34375,\n",
       " 'eval_nq_tiny_num_pred_words': 24.5234375,\n",
       " 'eval_nq_tiny_bleu_score': 30.490908221263297,\n",
       " 'eval_nq_tiny_bleu_score_sem': 2.107989256173362,\n",
       " 'eval_nq_tiny_rouge_score': 0.6546635742200725,\n",
       " 'eval_nq_tiny_exact_match': 0.0078125,\n",
       " 'eval_nq_tiny_exact_match_sem': 0.0078125,\n",
       " 'eval_nq_tiny_emb_cos_sim': 0.9054075479507446,\n",
       " 'eval_nq_tiny_emb_cos_sim_sem': 0.005778878864240689,\n",
       " 'eval_nq_tiny_perplexity': 2.8356816321783884,\n",
       " 'eval_nq_tiny_runtime': 3.3791,\n",
       " 'eval_nq_tiny_samples_per_second': 37.879,\n",
       " 'eval_nq_tiny_steps_per_second': 0.296}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = corr_trainer.inversion_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"nq\"].select(range(128)),\n",
    "    metric_key_prefix=\"eval_nq_tiny\",\n",
    ")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "551720c0-8724-427f-b696-0e48968b6cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000060009c48b00000731'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs0000000580099c0c00000733'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000068011300f00000732'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000050005e42700000730'\n",
      "generating from val:  96%|█████████████████████████████████████████████████████████████████████████████████▌   | 24/25 [27:26<01:08, 68.46s/it]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "  File \"/home/jxm3/.conda/envs/torch/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000088009ec1c00000735'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000008007f698500000737'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs00000007007ef60400000738'\n",
      "OSError: [Errno 16] Device or resource busy: '.nfs000000078011310e00000736'\n",
      "                                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pred] to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "[true] to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact\n",
      "\n",
      "\n",
      "\n",
      "[pred] individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "[true] individual from the Southern Hemisphere, to win a Winter Olympic gold medal and was also part of the short track relay team that won Australia'\n",
      "\n",
      "\n",
      "\n",
      "[pred] the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n",
      "[true] the same rights as straight people, while 15% disagreed. Additionally, 69% agreed that they should be protected from workplace discrimination. 13% of H\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6482889652252197,\n",
       " 'eval_pred_num_tokens': 31.0,\n",
       " 'eval_true_num_tokens': 32.0,\n",
       " 'eval_token_set_precision': 0.9905860805860806,\n",
       " 'eval_token_set_recall': 0.9905860805860806,\n",
       " 'eval_token_set_f1': 0.9905860805860806,\n",
       " 'eval_token_set_f1_sem': 0.005282719992297588,\n",
       " 'eval_n_ngrams_match_1': 24.27,\n",
       " 'eval_n_ngrams_match_2': 22.92,\n",
       " 'eval_n_ngrams_match_3': 21.74,\n",
       " 'eval_num_true_words': 24.54,\n",
       " 'eval_num_pred_words': 24.54,\n",
       " 'eval_bleu_score': 97.01666370750802,\n",
       " 'eval_bleu_score_sem': 1.3311970375686453,\n",
       " 'eval_rouge_score': 0.9908613229907346,\n",
       " 'eval_exact_match': 0.94,\n",
       " 'eval_exact_match_sem': 0.023868325657594204,\n",
       " 'eval_emb_cos_sim': 0.9989110827445984,\n",
       " 'eval_emb_cos_sim_sem': 0.000552708562463522,\n",
       " 'eval_runtime': 1727.0768,\n",
       " 'eval_samples_per_second': 0.058,\n",
       " 'eval_steps_per_second': 0.014}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_trainer.return_best_hypothesis = False\n",
    "corr_trainer.args.per_device_eval_batch_size = 4\n",
    "corr_trainer.gen_kwargs = {\n",
    "    \"early_stopping\": False,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "}\n",
    "corr_trainer.num_gen_recursive_steps = 50\n",
    "corr_trainer.sequence_beam_width = 8\n",
    "corr_trainer.return_best_hypothesis = True\n",
    "metrics = corr_trainer.evaluate(\n",
    "    eval_dataset=corr_trainer.eval_dataset[\"nq\"].select(range(100)),\n",
    "    metric_key_prefix=\"eval\",\n",
    ")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5987e3eb-b6df-4bce-b0fc-abb57ac347d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "et = corr_trainer.embedder_tokenizer\n",
    "true_str = et.batch_decode(inv_trainer.preds_sample_labels_list, skip_special_tokens=True)\n",
    "pred_0_str = et.batch_decode(inv_trainer.preds_sample_list, skip_special_tokens=True)\n",
    "pred_50_str = et.batch_decode(corr_trainer.preds_sample_list, skip_special_tokens=True)\n",
    "\n",
    "df = pd.DataFrame(zip(true_str, pred_0_str, pred_50_str), columns=['true', 'pred_0', 'pred_50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "926895e6-5530-4152-b807-3f68426d1d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to the character of the sutures of the skull w...</td>\n",
       "      <td>to the character of the skull, which are relat...</td>\n",
       "      <td>to the character of the sutures of the skull w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>individual from the Southern Hemisphere, to wi...</td>\n",
       "      <td>individual from the Southern Hemisphere to win...</td>\n",
       "      <td>individual from the Southern Hemisphere, to wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the same rights as straight people, while 15% ...</td>\n",
       "      <td>the same rights as men, and 75% agreed that th...</td>\n",
       "      <td>the same rights as straight people, while 15% ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bruthen, Victoria Bruthen is a small town loca...</td>\n",
       "      <td>Bruthen, Victoria Bruthen is a small town loca...</td>\n",
       "      <td>Bruthen, Victoria Bruthen is a small town loca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Castle Vale Castle Vale is a housing estate lo...</td>\n",
       "      <td>Castle Vale Castle Vale is a castle located be...</td>\n",
       "      <td>Castle Vale Castle Vale is a housing estate lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                true   \n",
       "0  to the character of the sutures of the skull w...  \\\n",
       "1  individual from the Southern Hemisphere, to wi...   \n",
       "2  the same rights as straight people, while 15% ...   \n",
       "3  Bruthen, Victoria Bruthen is a small town loca...   \n",
       "4  Castle Vale Castle Vale is a housing estate lo...   \n",
       "\n",
       "                                              pred_0   \n",
       "0  to the character of the skull, which are relat...  \\\n",
       "1  individual from the Southern Hemisphere to win...   \n",
       "2  the same rights as men, and 75% agreed that th...   \n",
       "3  Bruthen, Victoria Bruthen is a small town loca...   \n",
       "4  Castle Vale Castle Vale is a castle located be...   \n",
       "\n",
       "                                             pred_50  \n",
       "0  to the character of the sutures of the skull w...  \n",
       "1  individual from the Southern Hemisphere, to wi...  \n",
       "2  the same rights as straight people, while 15% ...  \n",
       "3  Bruthen, Victoria Bruthen is a small town loca...  \n",
       "4  Castle Vale Castle Vale is a housing estate lo...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b41ad53c-2fda-4d50-b95e-6cbd7f3e1b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"true\"] == df[\"pred_50\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b72d7a9-92e2-465f-8807-4c5973abc7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"true\"] == df[\"pred_0\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2a69d6f-3d38-412c-b495-ff651f0d6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"nq__32__sampled_outputs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58953fad-6fc4-489d-9a24-b96151356da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
