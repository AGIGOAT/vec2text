{"eval_loss": 1.5961565971374512, "eval_pred_num_tokens": 72.51515197753906, "eval_true_num_tokens": 76.46464538574219, "eval_token_set_precision": 0.777611333897232, "eval_token_set_recall": 0.830089490395857, "eval_token_set_f1": 0.8000088780365121, "eval_token_set_f1_sem": 0.01817750430895269, "eval_n_ngrams_match_1": 39.111111111111114, "eval_n_ngrams_match_2": 25.03030303030303, "eval_n_ngrams_match_3": 18.363636363636363, "eval_num_true_words": 54.535353535353536, "eval_num_pred_words": 53.05050505050505, "eval_bleu_score": 53.56263380192172, "eval_bleu_score_sem": 3.280848629776856, "eval_rouge_score": 0.8022918726287959, "eval_exact_match": 0.23232323232323232, "eval_exact_match_sem": 0.04266016017054685, "eval_emb_cos_sim": 0.9899854063987732, "eval_emb_cos_sim_sem": 0.0013850940868364047, "eval_runtime": 13112.2337, "eval_samples_per_second": 0.008, "eval_steps_per_second": 0.008, "_eval_args": {"alias": "openai_msmarco__msl128__200epoch__correct", "num_samples": 99, "return_best_hypothesis": 1, "num_gen_recursive_steps": 50, "sequence_beam_width": 8, "beam_width": 1, "dataset": "climate-fever"}}